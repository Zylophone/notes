* Big O Notation
** Definition
How time scales with respect to the data input
** Different Steps Get Added
#+BEGIN_SRC ruby
a = Array.new(n)
b = Array.new(m)
a.each do |element|
  ...
end
b.each do |element|
  ...
end
#+END_SRC

The runtime complexity of this algorithm is `O(n + m)`
** Drop Constants
You are interested on describing the relationship between the input data and how time scales. Constants
won't change the type of the curve.
** Different Inputs, Different Variables
If data is coming from different inputs, use different variables to describe them.
** Drop non-dominant terms
`O(n + log n)` ~ `O(n)`; `O(n^2 + n)` ~ `O(n)`
** Types of Runtime Complexity
| Type      | Name             | Description                                      | Example                                                      |
|-----------+------------------+--------------------------------------------------+--------------------------------------------------------------|
| O(1)      | Constant Time    | Operation does not depend on the input size      |                                                              |
| O(lg n)   | Logaritmic Time  | n is the size of the input; lg is base of 2      | Binary Search. It always drops half of the data in each step |
| O(n)      | Linear Time      | Direct proportion with respect of the input size | Insert elements in a sorted array                            |
| O(n lg n) |                  | Divide and Conquer                               | Merge Sort, Heap Sort                                        |
| O(n^2)    | Cuadratic Time   | Pair of nested loops; Fast growth rate           | Matrix Multiplication, Bubble sort.                          |
| O(n^3)    | Cubic Time       | 3 nested loops                                   |                                                              |
| O(2^n)    | Exponential Time | Dynamic Programming                              |                                                              |
** Rules
  - Additional constants might need to be dropped
  - Smaller order are not significant
  - Constant multiplication is not significant
** Case Analysis
*** Best Case
Little contribution
*** Worst Case
Upper bound
*** Average Case
Relies on Probability
*** Space Analysis
How much extra space a solution needs
* Data Structures
** Linear
*** Array
- Elements can be accessed by using an index
  - 0 <= index <= n - 1
  - 0    : lower bound
  - n -1 : upper bound
- Size of an array must be provided at compile time.
- Stores homogeneous elements at contiguous locations.
  - Depending on the type of the elements, index may be affected
  - base address + (index * size of the element)
**** Advantages
  - Possible single variable
  - Direct Access
  - Easy to construct and use arrays
  - They are indispensable on implementing iterative algorithms
  - Multiple Dimensional Array facilitates organizing data in a hierarchical way
**** Drawbacks
  - Memory allocated of the array cannot be released until program execution is finished
    - is this because array is stored on the heap(?)
  - Array size cannot be increased or decreased during runtime
    - This is a problem when dealing with unpredictable large dataset size
  - Variable large strings cannot be stored in arrays
  - Insertion/Deletion --> not performant
  - Allocated out of the memory namespace of the program
  - `c`,`c++` do not perform range checks at runtime
**** Operations
  - search
  - insert : shift elements to the right (ordered array)
  - delete : shift to the left; does not free any memory
**** Unsorted Array
***** Search
#+BEGIN_SRC ruby
def search(arr, element)
  exists = false
  arr.each do |ele|
    if ele == element
      exists = true
      break
    end
  end
  exists
end
#+END_SRC
***** Insert
#+BEGIN_SRC ruby
def insert(arr, index, element, capacity)
  if index == capacity
    index
  else
    arr[index] = element
    index + 1
  end
end

def main(array_size)
  arr = Array.new(array_size)
  current_index = 0
  (1.. (array_size + 100)).each do |element|
    current_index = insert(arr, current_index, element, array_size)
  end
  arr
end
#+END_SRC
***** Delete
#+BEGIN_SRC ruby
def search(arr, size, key)
  position = -1
  (0..(size - 1)).each do |index|
    if arr[index] == key
      position = index
    end
  end
  position
end

def my_print(arr, current_index)
  (0..current_index.each do |index|
    puts arr[index]
  end
end

def delete(arr, size, element)
  index = search(arr, size, element)
  return size if index == -1

  #this is equivalent to for(i=index, i < n -1, i++)
  (index..(size - 2)).each do |current_index|
    arr[current_index] = arr[current_index + 1]
  end
  size - 1
end
#+END_SRC

**** Sorted Array
***** Search
If array is sorted, binary search can be used to find the key
#+BEGIN_SRC ruby
def binary_search(arr, low, high, key)
  return -1 if low > high
  mid = low + (high - low)/2
  if arr[mid] == key
    return mid
  end
  if key < arr[mid]
    binary_search(arr, low, mid - 1, key)
  else
    binary_search(arr, mid + 1, high, key)
  end
end
#+END_SRC
***** Insert
Can I do it better? I started from start to end. What would happen if I start from end to start?
#+BEGIN_SRC ruby
def insert(arr, current_index, capacity, key)
  return current_index if current_index == capacity
  position = -1
  (0..current_index).each do |index|
    if arr[index] > key
      position = index
      break
    end
  end
  return current_index if position == -1
  (position..current_index + 1).each do |index|
    old = arr[index]
    arr[index] = key
    key = old
  end
  current_index + 1
end
#+END_SRC
***** Delete
#+BEGIN_SRC ruby
def delete(arr, current_index, capacity, key)
  position = binary_search(arr, 0, current_index,  key)
  return current_index if position == -1
  (position..current_index-1).each do |index|
    arr[index] = arr[index+1]
  end
  current_index - 1
end

#+END_SRC
*** Multiple Dimensional Array
  - Represent a smaller groups of elements within another group
  - rows and columns
  - two indexes: one for rows another one for columns
  - base address is again important(!!), because it helps us to traverse the array
**** 2 dimensional Array
  - Suppose that we want to store the grades of all the classes for a given student
| class0, grade0 | class0, grade1 |
| class1, grade0 | class1, grade1 |
  - rows represent classes
  - columns represent grades
  - You can think of this as a grouping per grades at the *class* level *or* a grouping per class at the *grade* level.
**** 3 dimensional Array
  - It's compose by 1 dimensional array plus a 2 dimensional array
  - Suppose that we want to store the grades of all the classes for a given group of students
| student0 |
| student1 |
  - In each "student" position, there will be stored a 2 dimensional array
  - You can think about this as a grouping per of grades and classes at the *student* level.
**** String Arrays
  - String is a sequence of chars with the last element being `\0` (empty string)
  - Having an array of string is useful when processing words (text processor)
  - Because of the nature of string their size is not fixed, but arrays need to have a fixed size, thus `\0` string is needed
**** Applications
  - Used in Graphs
  - Used in Imaging Processing
  - Solve Equations
  - Square Matrix: n, m; m = n
  - Symmetric Matrix: elements below and above the diagonal are the same
    - Distances from city a -> b and b -> a
  - Sparse Matrix
    - Majority of the values are zeros.
  - Triggenal Matrix
    - This type of matrixes can be stored in an array. All the elements above the diagonal are zeros.
**** Operations
  - Addition
***** Multiplication                                                            :TODO:
    - PLEASE, PLEASE, PLEASE, watch Matrix Multiplication videos!!!
*** LinkedList
  - Elements (nodes) are not stored at contiguous location
  - Elements are linked using pointers
  - Useful when frequent insertion and deletion of data elements!
  - Compiler dynamically allocates memory (in the heap) when a new node is created
  - Delete operation really frees memory and that memory can be recycle for the next node that will be used.
**** Implementations
***** Pointer Implementation
  - node {data: "chicago", next: <memory_address>}
  - Node is called recursive type because it points to the same point
  - Insert before and deleting node operations need *two pointers*!
  - Sorting takes O(n^2)
****** Advantages
  - Size can be adjusted
  - insert/deletion is O(1) {head}
****** Disadvantages
  - Not Random Access
  - Extra Space
****** Applications
   - Store and process polynomials
     - coefficients are stored in a linked list
     - missing terms are not represented in the linked list
   - Two dimensional Array
   - Queues, Trees, Graphs, Heaps
***** Cursor Implementation
  - Implicit or Explicit pointers
  - Two Arrays are used
    - Addresses
    - Data/Values
  - Size cannot changed dynamically
**** Advantages over Array
  - Dynamic Size; no need to know the size in advance
  - Ease of insertion/deletion
**** Disavantages
  - Random Access is not allowed; binary search is not possible
  - Extra memory space for storing the pointer
**** Structure
#+BEGIN_SRC ruby
class Node
  attr_accessor :data, :next
  def initialize(data, next_node = nil)
    self.data = data
    self.next = next_node
  end
end

class LinkedList
  attr_accessor :head
  def initialize(head = nil)
    self.head = head
  end
end
#+END_SRC
**** Traversal
#+BEGIN_SRC ruby
def my_print(linked_list)
  current = linked_list.head
  while current != nil
    puts current.data
    current = current.next
  end
end
#+END_SRC
**** Insertion
#+BEGIN_SRC ruby
class LinkedList
  def push(element)
    node = Node.new(element, self.head)
    self.head = node
  end

  def insert_after(current_node, element)
    node = Node.new(element, current_node.next)
    current_node.next = node
  end

  def append(element)
    node = Node.new(element)
    prev = nil
    current = self.head
    while current != nil
      prev = current
      current = current.next
    end
    if self.head.nil?
      self.head = node
    else
      prev.next = node
    end
  end
end
#+END_SRC
**** Deletion
#+BEGIN_SRC ruby
class LinkedList
  def deleteNode(key)
    current = self.head
    while current.next != nil
      if current.next.data == key
        current.next = current.next.next
        break
      end
      current = current.next
    end
  end

  def deleteNodeByPosition(position)
    return if self.head == nil

    if position == 0
      self.head = self.head.next
      return
    end

    index = 0
    current = self.head
    while current.next != nil
      if index + 1 == position
        current.next = current.next.next
        break
      end
      current = current.next
      index = index + 1
    end
  end
end
#+END_SRC
*** Circular Linked List
  - Elements are connected to form a circle
  - Process that are being executed in cycles
    - Processes scheduling
**** Advantages
- Any node can be the starting point
- Queue can be implemented by using CircularLinkedList
  - Front can be always be reached from the next of the last node added
- It's useful if you have to go repeatedly over the list
***** Used to process strings <<READ MORE ABOUT THIS!!!!                        :TODO:
  - Concatenation
  - Split
**** Disadvantages
  - Traversal can go in an infinite loop if first node is not well defined
**** Traversal
#+BEGIN_SRC ruby
def print_list(node)
  current = node
  loop do
    print current.data
    current = current.next
    break if current == node
  end
end
[1]->[2]->[3]--|
 ^             |
 |=============|
#+END_SRC
*** Doubly Linked List
  - Bidirectional traversal
**** Advantages
  - It can be traversed both ways
  - Insert/Delete operation is more efficient if pointer to the node is given
  - Ordered lists can be printed in ascending or descending order
**** Disadvantages
  - Extra Space
  - Have to be careful with Next and Prev pointers
**** Disavantages over LinkedList
  - An extra pointer is needed
  - prev pointer needs to be maintain
**** Structure
#+BEGIN_SRC ruby
class Node
  attr_accessor :data, :prev, :next
  def initialize(data, next_node=nil, prev=nil)
    self.data = data
    self.next = next_node
    self.prev = prev
  end
end

class DoublyLinkedList
  attr_accessor :head
  def initialize(node)
    self.head = node
  end
end
#+END_SRC
**** Insertion
#+BEGIN_SRC ruby
class DoublyLinkedList
  def push(data)
    node = Node.new(data, self.head)
    self.head.prev = node
    self.head = node
  end

  def append(data)
    current = self.head
    while current.next != nil
      current = current.next
    end
    node = Node.new(data)
    node.prev = current
    current.next = node
  end

  def insertAfter(data, node)
    new_node = Node.new(data, node.next, node)
    node.next.prev = new_node
    node.next = new_node
  end

  def insertBefore(data, node)
    new_node = Node.new(data, node, node.prev)
    node.prev.next = new_node
    node.prev = new_node
  end

  def printAll
    current = self.head
    while current != nil
      puts current.data
      current = current.next
    end
  end
end
#+END_SRC
**** Reverse
#+BEGIN_SRC ruby
class DoublyLinkedList
  def reverse
    current = self.head
    temp = nil
    loop do
      temp = current.prev
      current.prev = current.next
      current.next = temp
      current = current.prev
      break if current == nil
    end
    if temp != nil
      self.head = temp.prev
    end
  end
end
H
| -> ->
V
1  2  3
 <- <-
      H
 <- <-|
      V
1  2  3
 -> ->

nil <- 1 -> 2
2   <- 1 -> nil

#+END_SRC
*** Multi List                                                                  :TODO:
  - I think this is a form of 3 dimensional array
*** Stack
  - Stack can be implemented by an array or linked list.
  - Use for infix, postfix, and prefix notation
  - Subprogram calls (representation of a call stack)
  - Can represent piles of tree, bundles of office files, arrangement of envelops
**** Purpose
  - Mantaining Function Calls
  - Recursion can be removed by using stacks
  - Reversing words
  - Balanced parenthesis
    - Grouped Statements
  - Undo operations (last operation)
  - Implement back functionality in a browser
  - Implementing search and traversal (iterative approach) ~~ Backtracking
  - Infix to Postfix notation
**** Using stacks in function calls
  - Stack holds the history of calls
  - Each call is saved in the stack by using a data structure called stack frame
    - Function Arguments
    - Return Address
    - Local Variables
*** Queue
  - Queue can be implemented by an array or linked list.
  - Collection of Homogeneous elements
  - Rear  <-- push
  - Front <-- pop
**** Purpose
  - Collection of Elements First In, First Out
  - Operations
    - enqueue -> element added to the "rear"
    - dequeue -> element removed from the "front"
  - When data is transferred asynchronously
    - IO Buffers, Pipes, File IO
  - Breadth-First Search
  - CPU Scheduling, Disk Scheduling
**** Implementation
  - Array: The problem is with unused positions. Front moves to the right always.
  - Linked List:

*** Circular Queues
  - Useful when using array implementation
  - Used in scheduling
*** Priority Queues
  - Elements are sorted by priority
  - It's useful when managing processes
**** Implementation
  - Heap design O(lg N)
  - Array based O(N)
  - Linked Based O(N)

*** Dequeue
  - Data can be added from two ends
  - Data can be deleted from two ends
  - Behaves as a stack and a queue
**** Implementation
  - Array: Circular Array
  - Linked List:
*** Hash Table
  - Try to use it as the first data structure solution!!
  - Key => Value lookup
  - Good Hash Function
    - Makes use of all info provided by key
    - Use fast operations
    - Uniformly distributes output across table
    - Maps similar keys to very different hash values
    - input is a string the output is a hash code and then an index is output
  - get/set is O(1) in theory
  - If hash function is bad then O(n)
**** Collisions
  - Chaining
    - store the value with the key in a linked list
** Tree Based
*** Tree
  - Hierarchical Relationship
  - Collection of nodes such that:
    - There is a root
    - Nodes are connected through edges
    - One path from one node to another
    - Nodes are connected from top to bottom
**** Definitions and Terminology
  - Parent Node
  - Root Node has not parent
  - Child Node
  - Siblings
    - Children which have a common parent are collectively known as siblings
  - Ancestors
    - All nodes that appear on the path to the root
  - Descendants
  - Subtree
***** Tree Level
#+BEGIN_SRC ruby
  0 -->       (A)
  1 -->   (B)     (C)
  2 --> (D) (E) (F) (G)
#+END_SRC
***** Tree Height
  - Plays a crucial role in determining the performance of the search algorithm
  - A tree with a shorter path can be searched faster than one with longer path
***** Important Characteristics
  - Non-linear data structure
  - There exist a unique path from the root to any of the nodes.
***** Forest
  - A set of disjoint three structures
***** Classification of Trees
  - Based on maximum children permissible to be attached
  - n-aray or n-way tree
  - Multiways trees frequently used buy modern database management systems.
    - Height is kept to the minimum
    - B  Tree  ::= File Systems -> read & write large blocks of data
    - B+ Tree  ::=
    - A range is used
#+BEGIN_SRC ruby
         [5       10]
  [1 2 3]  [6 7 8]  [11 13 15]
#+END_SRC
**** Application of Trees
  - Organization of a company
  - Table of the contents of a book
  - Structure of a file system
#+BEGIN_SRC ruby
                       (/root)
             (dir)       (dir)    (dir)
    (sub dir)    (file)  (file)   (file)
 (file)  (file)
#+END_SRC
**** Binary Tree
  - left child  -> first
  - right child -> second
**** Full Binary Tree
  - 2^(h+1) - 1  == Total Nodes
  - log(n+1) - 1 == Height
#+BEGIN_SRC ruby
        (0)
   (0)      (0)
(0)  (0)  (0) (0)
#+END_SRC
**** Complete Binary Tree
  - Left most position is filled
  - All nodes up to level h-1 are present
  - This is a valid complete binary tree
#+BEGIN_SRC ruby
        (0)
   (0)      (0)
(0)  (0)
#+END_SRC
  - This is *not* a valid complete binary tree
#+BEGIN_SRC ruby
        (0)
   (0)      (0)
     (0)  (0) (0)
#+END_SRC
**** Ordered Search Trees
  - Duplicate keys are not allowed
#+BEGIN_SRC ruby
       (X)
  (â‰¤ X)  ( > X)
#+END_SRC
**** Expression Trees
  - A + B
    #+BEGIN_SRC ruby
       (+)
    (A)   (B)
    #+END_SRC
  - B + A
    #+BEGIN_SRC ruby
       (+)
    (B)   (A)
    #+END_SRC
**** Heap
  - Data value in any node is greater than all values held in the left and right subtree
#+BEGIN_SRC ruby
         (80)
     (50)    (60)
  (45) (42)
#+END_SRC
  - Represents a Priority Queue
  - Can be used in Searching Algorithms
**** Binary Decision Trees
  - Represents a sequence of if-then-else conditions and resulting actions
  - Applications in Artificial Intelligence and Expert Systems
#+BEGIN_SRC ruby
                (condition 1)
     (condition 2)          (action 1)
 (action 2)  (action 3)
#+END_SRC
**** Implementation
  - Linear Representation (array)
    - Skewed tree will result in waste of space
    - Three Arrays
      - value
      - left
      - right
  - Link Representation (nodes)
    - Storage space is allocated dynamically
**** Traversal
  - Each node is visited only once
  - Preorder  -> root, preorder(left) and preorder(right)
  - Inorder   -> inorder(left), root, inorder(right)
  - Postorder -> postorder(left), postorder(right), root
#+BEGIN_SRC ruby
  0 -->       (A)
  1 -->   (B)     (C)
  2 --> (D)         (E)
#+END_SRC

  - preorder:  A->B->D->C->E
  - inorder:   D->B->A->C->E
  - postorder: D->B->E->C->A
***** Preorder
****** Functional
#+BEGIN_SRC ruby
def preorder(node = root)
  print node->data
  preorder(node->left)
  preorder(node->right)
end
#+END_SRC
****** Stack Based Preorder
  - Elements that are at the right always go to the stack; the one on the left are process immediately
  - Until left is null; if so, pop from the stack and keep going
***** inorder
****** Functional
#+BEGIN_SRC ruby
def Inorder(node = root)
  inorder(node->left)
  print node->data
  inorder(node->right)
end
#+END_SRC
****** Stack Based Inorder
  - current = root
  - repeat steps 3 through 4 until current is not null
  - proceed down the left most subtree rooted at current, pushing onto the stack addresses of node on the way. keep until leaf node is reached
  - pop off the stack and process the popped node. if stack.empty?. if popped node has a right child assign current pointer to the right child and go to.
***** Postorder
****** Functional
#+BEGIN_SRC ruby
def postorder(node = root)
  postorder(node->left)
  postorder(node->right)
  print node->data
end
#+END_SRC
****** Stack Based Postorder
  - Uses a special character '$'
  - Assign a current pointer current to the root node, then repeat step 2 to 3 until the stack is empty
  - Traverse down the left-most path of the three root at current. At each node push the address onto the stack. If there is a right child, push its address to the stack by flagging with '$'. Continue until leaf node is reached.
  - Pop and process all nodes which do not have the flag '$'. If the stack is empty, exit. If a node with '$' flag is popped, remove the flag and assign current pointer to the right child. Perform 2.
*** Binary Search Tree
  - data is considered as "key"
  - types:
    - skewed left --> linked list
    - skewed right -> linked list
    - full tree
    - complete tree
    - incomplete tree
  - Searching for the minimum key --> go all the way to the left
  - Searching for the maximum key --> go all the way to the right
  - Performance: search is proportional to the height of the binary tree
    - H = lg(n+1) - 1
    - Runtime Performance is O(lg n)
    - With huge amount of data the height of the tree should be kept to the barest minimum
      - complete or full.
  - inorder traversal produces sorted order.
**** Structure
#+BEGIN_SRC ruby
class Node
  attr_accessor :data, :left, :right
  def initialize(data, left=nil, right=nil)
    self.data = data
    self.left = left
    self.right = right
  end
end

class BinarySearchTree
  attr_accessor :root, :prev, :side
  def initialize(root=nil)
    self.root = root
    self.prev = nil
    self.side = nil
  end
end
#+END_SRC
**** Operations
***** Node Deletion
Three Cases:
  1. Node to be deleted is a leaf
  2. Node to be deleted has a right children
  3. Node to be deleted has a left children but does not have a right children

- For (1); Free the pointer to the node. Done.
- For (2); Keep a reference to the node that will be deleted; Find the minimum element that belongs to the *right* subtree; Once you find the minimum node, interchange the values; call delete method again but now pass the reference to the minimum node.
- For (3); Keep a reference to the node that will be deleted; Find the maximum element that belongs to the *left* subtree; Once you find the minimum node, interchange the values; call delete method again but now pass the reference to the maximum node.
#+BEGIN_SRC ruby
class BinarySearchTree
  def find_node(key)
    current = self.root
    self.prev = nil
    node = nil
    while !current.nil?
      if current.data == key
        node = current
        break
      elsif key > current.data
        self.prev = current
        self.side = :right
        current = current.right
      else
        self.prev = current
        self.side = :left
        current = current.left
      end
    end
    node
  end

  def delete_node(key)
    current = self.find_node(key)
    while !current.nil?
      if current.data == key && current.right.nil? && current.left.nil?
        self.prev.send("#{self.side}=", nil)
        break
      elsif current.data == key && !current.right.nil?
        minimum = self.find_minimum(current.right)
        self.prev = current
        self.side = :right
        current.data = minimum.data
        current = minimum
        key = minimum.data
      else
        maximum = self.find_maximum(current.left)
        self.prev = current
        self.side = :left
        current.data = maximum.data
        current = maximum
        key = maximum.data
      end
    end
  end

  def find_minimum(node)
    self.prev = nil
    self.side = nil
    current = node
    while !current.nil? && !current.left.nil?
      self.prev = current
      self.side = :left
      current = current.left
    end
    current
  end

  def find_maximum(node)
    self.prev = nil
    self.side = nil
    current = node
    while !current.nil? && !current.right.nil?
      self.prev = current
      self.side = :right
      current = current.right
    end
    current
  end
end
#+END_SRC

*** Heap
**** Properties
In the binary tree implementation the following properties must be observed:
- It's a complete tree (all levels are filled except the last)
- Leaves are allocated as left as possible
- Min heap and Max heap can be efficiently implemented by using a binary tree
- If Min Heap, the root is the smallest element in the collection. This applies to all subtrees
- If Max Heap, the root is the greates element in the collection. This applies to all subtrees
**** Structure
It's observed that a complete tree can be implemented by using an array:
| root | parent node | left node | right node |
|------+-------------+-----------+------------|
|    0 | i/2         | 2*i + 1   | 2*i + 2    |
#+BEGIN_SRC ruby
class MinHeap
  attr_accessor :max, :index, :tree
  def initialize(max=10)
    self.index = 0
    self.max = max + 1
    self.tree = Array.new(self.max)
  end
end
#+END_SRC
**** Operations
***** Addition
Inserts the new element at the end; if the element is greater than its parent interchange them; done otherwise
#+BEGIN_SRC ruby
class MinHeap
  def add(element)
    return if self.index == self.max - 1
    self.index = self.index + 1
    self.tree[self.index] = element
    heapify_up
  end

  def heapify_up
    index = self.index
    while index > 1
      parent_node = index/2
      break if self.tree[index] > self.tree[parent_node]

      tmp = self.tree[parent_node]
      self.tree[parent_node] = self.tree[index]
      self.tree[index] = tmp
      index = parent_node
    end
  end
end
#+END_SRC
***** Deletion
Override the value of root with the last value of the tree; check that root is the smallest element in the tree;
if not, rotate from with the smallest; keep doing that until the condition is false.
#+BEGIN_SRC ruby
class MinHeap
  def delete
    return if self.index == 0
    top = self.tree[1]
    self.tree[1] = self.tree[self.index]
    self.index = self.index - 1
    heapify_down
    top
  end

  def heapify_down
    index = 1
    while index < self.index - 1
      break if self.tree[index] < self.tree[2*index]
      tmp = self.tree[index]
      if self.tree[2*index] > self.tree[2*index + 1]
        self.tree[index] = self.tree[2*index + 1]
        self.tree[2*index + 1] = tmp
        index = 2*index + 1
      else
        self.tree[index] = self.tree[2*index]
        self.tree[2*index] = tmp
        index = 2*index
      end
    end
  end
end
#+END_SRC
**** Application
- Heap Sort
- Priority Queue
*** Graph
  - Crossing a bridge without repeating a path once (Euler)
  - Collection of vertices and edges
  - Store some kind of data in the vertex
  - Edge represents a connection between a pair of vertices
  - G = (V, E)
  - V = {v1, v2, v,3}
  - E = {(v1, v2), (v1,v3)}
**** Types
  - Undirected: no direction, 1:1 relationship; N(N-1)/2 edges
  - Directed: there is direction, <U,V> (U points to V); diagraph || network
  - Weighted: edges have weight; cost of transportation; distance of cities
  - MultiGraph: generalization of directed graphs; multiple edges between the same vertices
**** Graph Paths
  - A sequence of edges that connect two vertices: <A, B, D, E>
  - Length: number of edges; when == 1 vertices are neighbors or adjacents
  - Reachable: if a path exists
  - Simple Path: a path that contains non repeated edges
  - Elementary Path: If a vertex is repeated
**** Graph Connectedness
  - Connected: if all vertices are reachable
    - simple for undirected graphs (no direction)
  - Weakly connected
    - if one or more of the vertices are not reachable: (A) is not reachable
    - (A)-->(B)
    - |     ^
    - ->(C)-|
  - Unilaterally connected
    - (A)-->(B) B is reachable from A, but A is not reachable from B
  - Strongly connected
    - One vertex is reachable from any other vertex
**** Loops and Cycles
  - Loop: An edge that start and terminates at the same vertex
  - Cycle: It's a path that originates and terminates on the same vertex, *but* includes more than one edge
  - Undirected graph
    - Cycles have a different meaning
    - At least 3 vertices need to be linked together to form a cycle A -- B is not a cycle!
**** Degree of Vertex
  - out-degree: number of edges that "originate" from the vertex
  - in-degree: number of edges that "terminate" in the vertex
**** Applications of Graphs
  - We use graphs to represent relationships between elements
  - Computer networks
  - Molecules structures
  - Databases
  - Find optimal paths
  - Identify what tasks can be executed in parallel (assembly line)
**** Operations on Graphs
  - Reachability of a vertex
  - Find paths of different lengths between a pair
  - Shortest path between a pair of designated vertices
  - Traversing a graph
**** Matrix Representation of Graphs
  - Adjacency Matrix || Bit Matrix || Weight Matrix
  - Degree calculation is easy: out-deg(row); in-deg(column)
  - Drawbacks:
    - insertion/deletion are complicated because it will require to modify row/column dynamically
    - waste of space for sparse graphs
  - Implementation
    - A two-dimensional array -> edges
    - A one-dimensional array -> vertices
**** Path Lengths in a graph
  - Matrix gives an efficient way to check if there is a path from one vertex to another
  - Square of adjacency matrix gives path of length Pi,j = Sum(i=1, n){ Aj,k * Ak,j}
  - A^n -> represents the number of paths of length n
**** Path Matrix
  - A would be reachable from B if there exists a path of any length
  - Does not contain any zeros --> strongly connected
  - Warshall's Algorithm for Path Matrix
    - Pi,j = Pi,j OR Pi,k AND Pk,j
**** Linked List Representation of Graphs
  - An Array that contains the vertices
  - A linked list per vertex that contains all the edges
**** Breadth-First search and its uses
  - Exploring a Graph
  - Route Finding || path search
    - The parent of a node will change depending on the type of search that's performed
  - For packman the subject cannot move diagonally
  - Find shortest path from a given source vertex in terms of the number of edges in the path
  - This algorithm always visite "neighbor" first
    - To do so, a Queue is used
    - Some people like to think about this traversal as a ripple
  - The vertex of the graph can be states or whatever you want
***** Applications
  - Web Crawling --> visit neighboors and not descendants
  - Social Networking (levels of separations -- layers -- ripple effect)
  - Network Broadcast
  - Garbage Collection --> "unreachable variables"
  - Model Checking --> test if states are reachable
  - Checking Mathematical conjecture
  - Solving Puzzles & games
    - Always start at the solved state and then move to the other possible states
    - The height of the resulting graph is called the *diameter* of the graph
  - O(|V| + |E|)
    - An Array of Vertices
    - Each position of the array will contain a pointer to a linked list that has the edges
    - A vertex is visited just once
***** Traversal
#+BEGIN_SRC ruby
  0 -->       (A)
  1 -->   (B)     (C)
  2 --> (D) (E) (F) (G)
  result: (A), (B), (C), (D), (E), (F), (G)
#+END_SRC
  - Visit all nodes reachable from give s belongs to V
  - O(V+E) time
  - Look at nodes reachable in 0 moves, 1 move, 2 moves, ....
  - Avoid visiting twice a given vertex.
**** Depth-First search
  - It goes as deeply as it can before "backtracking"
  - Recursively explore graph, backtracking as necessary
  - The visit of a given node is done with all the descendants has been traversed
  - Be careful of not visiting a vertex twice
  - Disconnected Graph --> need to traverse all the vertices
    - Top Level procedure traverse the list of the vertices
      - Recursive Procedure
  - O(V+E) linear time
***** Implementation
#+BEGIN_SRC ruby
class Vertex
  attr_accessor :label, :vertices
  def initialize(label)
    self.label = label
    self.vertices = []
  end
end

def buildAdjecencyList(vertex_labels, edges)
  vertices = vertex_labels.map{|label| Vertex.new(label)}
  edges.each do |from, to|
    vertices[from].vertices << to
  end
  vertices
end

def dfs_impl(current, adjecency_list, visited)
  return if visited[current.label]
  #init of traversal
  puts "****** starting #{current.label} ******"
  visited[current.label] = true
  current.vertices.each do |vertex|
    dfs_impl(adjecency_list[vertex], adjecency_list, visited)
  end
  puts "****** finishing #{current.label} ******"
end

def dfs(init, vertex_labels, edges)
  adjecency_list = buildAdjecencyList(vertex_labels, edges)
  visited = Array.new(adjecency_list.size, false)
  dfs_impl(adjecency_list[init], adjecency_list, visited)
end

def dfs_all(init, vertex_labels, edges)
  adjecency_list = buildAdjecencyList(vertex_labels, edges)
  visited = Array.new(adjecency_list.size, false)
  ([adjecency_list[init]] + adjecency_list).each do |vertex|
    next if visited[vertex.label]
    dfs_impl(vertex, adjecency_list, visited)
  end
end
#+END_SRC

***** Does it have a cycle
  - The logic here is to use an auxilary array to mark whether a node is being processed or not
  - The following is the recursive solution
#+BEGIN_SRC ruby
class Vertex
  attr_accessor :label, :vertices
  def initialize(label)
    self.label = label
    self.vertices = []
  end
end

def buildAdjecencyList(vertex_labels, edges)
  vertices = vertex_labels.map{|label| Vertex.new(label)}
  edges.each do |from, to|
    vertices[from].vertices << to
  end
  vertices
end

def dfs_impl(current, adjecency_list, visited, being_processed, flag)
  return true if being_processed[current.label]
  return false if visited[current.label]
  #init of traversal
  visited[current.label] = true
  being_processed[current.label] = true
  current.vertices.each do |vertex|
    flag = dfs_impl(adjecency_list[vertex], adjecency_list, visited, being_processed, flag)
    break
  end
  being_processed[current.label] = false
  flag
end

def is_dag?(init, vertex_labels, edges)
  adjecency_list = buildAdjecencyList(vertex_labels, edges)
  visited = Array.new(adjecency_list.size, false)
  being_processed = Array.new(adjecency_list.size, false)
  flag = false
  dfs_impl(adjecency_list[init], adjecency_list, visited, being_processed, flag)
end
#+END_SRC
  - An Iterative solution can be provided by using stack
    - The implementation is a bit more involved in the sense that:
      - the stack might contain elements of different types
      - the stack will contain vertices, but also
      - the stack will contain a special operation to mark a vertex as *not* being processed
    - In the iterative solution there is no natural way to know the begining *and* the end processing window of an element.
#+BEGIN_SRC ruby
class Vertex
  attr_accessor :label, :vertices
  def initialize(label)
    self.label = label
    self.vertices = []
  end
end

def buildAdjecencyList(vertex_labels, edges)
  vertices = vertex_labels.map{|label| Vertex.new(label)}
  edges.each do |from, to|
    vertices[from].vertices << to
  end
  vertices
end

def dfs_stack_impl(start_vertex, adjecency_list, visited, being_processed)
  stack = [[:process, start_vertex.label]]
  flag = false
  while !stack.empty?
    operation, current_label = stack.pop
    current = adjecency_list[current_label]
    case operation
    when :process
      if being_processed[current_label]
        flag = true
        break
      end
      next if visited[current_label]

      visited[current_label] = true
      being_processed[current_label] = true
      stack.push [:unprocess, current_label]
      current.vertices.each do |vertex|
        stack.push [:process, vertex]
      end
    when :unprocess
      being_processed[current_label] = false
    end
  end
  flag
end

def is_dag?(init, vertex_labels, edges)
  adjecency_list = buildAdjecencyList(vertex_labels, edges)
  visited = Array.new(adjecency_list.size, false)
  being_processed = Array.new(adjecency_list.size, false)
  dfs_stack_impl(adjecency_list[init], adjecency_list, visited, being_processed)
end
#+END_SRC
***** Edge Classification (Directed Graph)
  - Tree Edges (parent pointers)
    - Visit a new vertex via an edge
  - Forward Edges
    - Points to one of its descendants in the three
  - Backward Edges
    - Points to one of its ancestors in the three
  - Cross Edges
    - Any other edge.
***** Edge Classification (Undirected Graph)
  - Tree and Backward edges
  - Forward and Cross edges are not possible because they will be visited before.
***** Applications
  - Cycle detection
    - If there is a backward edge in DFS, then there is a cycle in the graph
    - Proof: G has a cycle <=> DFS has a backward edge
      - "<=" (left-hand side proof)
        - ()-->()-->()-->()
        - ^              |
        - |--------------|
        - the proof is evident
      - "=>" (right-hand side proof)
        - Uses the fact that (v_k, v_0) exists because v_0 is still being process when v_k is process
        - this is called parenthesis balanced (...(..)...)
        - DFS will keep chugging until there are no more descendants.
  - Topological Sort
**** Topological Sort
  - Job Scheduling
    - Given a directed acyclic graph (DAG) order vertices so that all edges point from lower order to higher order
    - Correctness of DAG
      - For any edge e = (u, v), v finishes before u finishes
      - Case 1: u starts before v
        - (u)-->(v) ;;we know this is true because v is a descendant of u
      - Case 2: v start before v
        - (u)-->(v)
        - ^     |
        - |-----|
        - But we know this is a contradiction because there are not backward edges in a DAG
  - An easy way to implement this is to use recursive dfs.
    - each element is push onto the stack when is done being process (after calling dfs on its children)
    - the reason behin tht is that the current element is fully processed or solved when all its children are solved.
    - this algorithm makes the assumption that the grap is DAG.
#+BEGIN_SRC ruby
class Vertex
  attr_accessor :label, :vertices
  def initialize(label)
    self.label = label
    self.vertices = []
  end
end

def buildAdjecencyList(vertex_labels, edges)
  vertices = vertex_labels.map{|label| Vertex.new(label)}
  edges.each do |from, to|
    vertices[from].vertices << to
  end
  vertices
end

def dfs_impl(current, adjecency_list, visited, stack)
  return if visited[current.label]
  #init of traversal
  visited[current.label] = true
  current.vertices.each do |vertex|
    dfs_impl(adjecency_list[vertex], adjecency_list, visited, stack)
  end
  stack.push current.label
  stack
end

def topological_sort(init, vertex_labels, edges)
  adjecency_list = buildAdjecencyList(vertex_labels, edges)
  visited = Array.new(adjecency_list.size, false)
  stack = []
  ([adjecency_list[init]] + adjecency_list).each do |vertex|
    next if visited[vertex.label]
    dfs_impl(vertex, adjecency_list, visited, stack)
  end
  stack
end
#+END_SRC
**** Parenthesis Theorem
#+BEGIN_SRC ruby
In a DFS traversal, nodes are finished once all their children are finished. If you mark the discover and finish times for each node during traversal, then you can check to see if a node is a descendant by comparing start and end times. In fact any DFS traversal will partition its edges according to the following rule.

Let d[node] be the discover time of node, likewise let f[node] be the finish time.

Parenthesis Theorem For all u, v, exactly one of the following holds:
1. d[u] < f[u] < d[v] < f[v] or d[v] < f[v] < d[u] < f[u] and neither of u and v is a descendant of the other.

d[u] < d[v] < f[v] < f[u] and v is a descendant of u.
d[v] < d[u] < f[u] < f[v] and u is a descendant of v.
So, d[u] < d[v] < f[u] < f[v] cannot happen.
Like parentheses: ( ) [], ( [ ] ), and [ ( ) ] are OK but ( [ ) ] and [ ( ] ) are not OK.]
#+END_SRC

**** Spanning Trees
  - N^(N-2) spanning trees
  - no cycles
  - depth-first search is used to create a spanning tree
  - breadth-first search is used to create a spanning tree
  - Minimum Spanning Trees
    - Lower travel cost
    - Minimum amount of cable
    - Kruskal's and Prim's Algorithm
  - Dijkstra's Algorithm
    - Trace of shortest path
*** Tries
  - Tree-like Data Structure
  - Efficient information retrieval data structure
  - Stores mainly characters
    - it can store numbers as well
  - A path represents a word or a part of a word
  - Key must be unique!!
    - Never have to deal with collisions
  - Fast lookup, fast insertion, fast deletion
  - Data is used as a road map
  - Prefix lookups
  - Great for word validation
    - Does this word belongs to the dictionary?
  - Find all the words
  - For multiple calls, the state can be stored in a given node.
**** Operations
  - search
    - prefix; whole word
  - insertion
  - deletion
    - whole word
      - delete node if it is a leaf; recurse to the parent
      - toggle flag of node if it's not a leaf; stop
    - prefix
**** Performance
  - search -> O(M); M being the length of the string
    - the penalty is in the storage
  - Insertion -> O(K) where K is the length of the string
  - Memory Requirements
    - O(alphabet_size * K * N)
**** Implementation
#+BEGIN_SRC ruby
class TrieNode
  attr_accessor :hash, :endOfWord
  def initialize()
    self.hash = {}
    self.endOfWord = false
  end

  def addNode(char)
    newNode = TrieNode.new
    self.hash[char] = newNode
    newNode
  end

  def getNodeBy(char)
    self.hash[char]
  end

  def contains?(char)
    self.hash.include?(char)
  end

  def leaf?
    self.hash.empty?
  end
end

class Trie
  attr_accessor :root
  def initialize()
    self.root = TrieNode.new
  end

  def insert(word)
    current = self.root
    word.split("").each do |char|
      if current.contains?(char)
        current = current.getNodeBy(char)
      else
        current = current.addNode(char)
      end
    end
    current.endOfWord = true
  end

  def search(word)
    current = self.root
    word.split("").each do |char|
      break if !current.contains?(char)
      current = current.getNodeBy(char)
    end
    current.endOfWord
  end

  def delete(word)
    current = self.root
    stack = []
    word.split("").each do |char|
      break if !current.contains?(char)
      stack.push [char, current]
      current = current.getNodeBy(char)
    end
    return false if !current.endOfWord

    if current.leaf?
      current = nil #free the current node
      while !stack.empty? || current.hash.length >= 1
        char, current = stack.pop
        current.hash.delete(char)
      end
    else
      current.endOfWord = false
    end
    true
  end
end
#+END_SRC
**** Exercises
***** Contact List
  - Print all the contacts that start with a given string.
#+BEGIN_SRC ruby
class TrieNodeHash
  attr_accessor :count, :hash, :endOfWord
  def initialize
    self.count = 0
    self.hash = {}
    self.endOfWord = false
  end

  def getNodeBy(char)
    self.hash[char]
  end

  def addNode(char, node)
    self.hash[char] = node
  end
end

class TrieNodeArray
  attr_accessor :count, :array, :endOfWord
  def initialize
    self.count = 0
    self.array = Array.new(26)
    self.endOfWord = false
  end

  def getNodeBy(char)
    self.array[index_array(char)]
  end

  def addNode(char, node)
    self.array[index_array(char)] = node
  end

  private
  def index_array(char)
    char.ord - 'a'.ord
  end
end

class Trie
  attr_accessor :root, :node_class
  def initialize(node_type)
    self.node_class = node_type.to_s.constantize
    self.root = self.node_class.new
  end

  def add(contact_name)
    current = self.root
    contact_name.split("").each do |char|
      node = current.getNodeBy(char)
      if node.nil?
        node = self.node_class.new
        current.addNode(char, node)
      end
      node.count += 1
      current = node
    end
    current.endOfWord = true
  end

  def find_count(prefix)
    current = self.root
    prefix.split("").each do |char|
      node = current.getNodeBy(char)
      current = node
      break if current.nil?
    end
    current.nil? ? 0 : current.count
  end
end
#+END_SRC
* Sorting
  - Organizing data items in ascending or descending order
  - Numerals are arranged according to their magnitude
  - Characters are arranged according to the Character Set: ASCII or UNICODE
** Benefits
  - Facilitates the search of a given elements
  - sorting/indexing is vital in databases
  - helps in identifying trends
** Types
  - internal sorting --> main memory (faster)
  - external sorting --> disk, magnetic tape (slower)
** Analysis of sorting algorithms
  - Accessing
  - Comparing
  - Swapping
  - Assigning
** Elementary Methods
  - They use iterative methods consisting of nested loops
  - Their efficiency is determine by the number of the loops
    - O(n^2)
  - Bubble sort, Insertion sort, Selection sort
** Advanced Methods
  - divide and conquer
  - recursive procedures
  - Quick sort, Heap sort, Merge sort
    - O(n * lg n)
  - Sometimes the efficiency of an algorithm also depends on the existing order of the data
    - Reversed order
    - Partial order
    - Randomly order
** Sort Passes
  - An array of "n" elements can be arranged in *n!* possible ways
** Methods
*** Bubble Sort
  - Compare adjacent data items and swap them if out of order
  - In each pass, the sub-array is reduced by one
**** Implementation
#+BEGIN_SRC ruby
(0..10).each do |i|
  (0..i).each do |j|
  end
end
#+END_SRC
**** Analysis
  - During Pass 1 --> N - 1
  - During Pass 2 --> N - 2
  - During Pass 3 --> N - 3
  - ............. --> N^2/2 - N/2 == O(n^2)
There is an improved version and it's O(n) when array is sorted
*** Selection Sort
  - Find the largest element
  - Exchange it with the last element
  - Decrease the range of sort by 1; so the last element becomes n - 1
**** Implementation
  - Holds the biggest elements
    - tmp data
    - tmp index
**** Analysis
  - O(n^2); two nested for loops
  - why number of exchanges are 3(n-1) and no 2n?

*** Insertion Sort
  - There exist two regions: sorted and unsorted
  - Elements have to be shifted to the right
**** Analysis
  - Two nested loops
  - n-1 passes
    - worst case n-1 == n(n-1)/2
  - 2(n-1) data moves
  - O(n^2 + n-2) operations
  - It performs better than bubble and selection sort
*** Shell Sort
  - Extension of the insertion sort
  - It compares elements that are distant apart == it's called increment
  - 4-sort, 2-sort, 1-sort ==> phases
**** Analysis
  - Increment set impacts the performance
  - 1,3,7,15 => O(n^(3/2))
  - Moderately large data set
*** QuickSort
  - 1960 C.A.R Hoare
  - Recursive procedure (divide and conquer)
  - Partition into two sub arrays, using a pivot
  - All elements, are moved so they are left than the pivot and greater to the pivot
  - Same thing is done recursively
**** Selection of Quicksort Pivot
  - This impacts performance
  - Random selection
    - safest choice but increases the running time
  - median-of-three
    - increases up to 5%~10% performance
    - (lower left + upper right)/2
**** Analysis
  - Partitioning array into two
    - An array of size 'n' can be split on lg(n+1) partitions
  - Comparisons of data elements
    - n comparisions
  - Swapping of out-of-order elements
    - n exchanges
  - 2*n*lg(n+1) => nlg(n)
**** Worst Case Scenario
  - O(n^2) when array is sorted
    - because bad pivot can cause n(n-1)/2 partition
  - Another drawback is that QuickSort is massively recursive
  - Small machines might have problems
*** Heap Sort
  - Special kind of binary tree
    - Complete tree
    - Each node is greater than both its right and left children
**** Analysis
  - Heapify: a binary tree of size n has lg(n) levels
    - O(4n lg n) ==> O(n lg n)
    - Slower than QuickSort
**** Advantages over QuickSort
  - It's not recursive, thus does not need stack memory (extra space)
  - More robust --> performance does not depend on the type of the data
  - Ideal for realtime situations where the order of data cannot be predicted
*** Merge Sort
  - Used to store data on magnetic tape files
  - It can be implemented as recursive or iterative
**** Analysis
  - Each pass the size is doubled => 1,2,4,8,.. this describes lg(n)
  - O(n lg n) -> because n comparisions are performed in each level
  - Faster than Heap Sort but slower than QuickSort
*** Radix Sort
  - H.H. Seward 1954
  - Least significant element of data type
    - Integer: 0-9
    - Chars: 0-26
    - Bits: 0-1
  - Creates buckets for each element
  - O(S*R*N) => O(N)
    - S = Maximum Size
    - R = Range or Radix
    - N = Size of data
  - Worst case O(n^2)
  - Space wise not efficient
*** External Sort
  - Records are read in blocks from external storage into main memory
  - Each block is sorted internally and written block to secondary storage
  - The resulting smaller set of files are merged into a single sorted file
  - Uses index files
  - Main File --> Index file for Id
              --> Index file for Name
  - Using Pointers
  - Original data is not touched
  - insertion/deletion of data can be done efficiently because only index files need to be touched
* Searching
  - Locating a given item in a data collection
  - Breadth-First Search
  - Depth-First Search
  - Binary Search
    - Sorted Arrays
    - Trees
  - Linear Search
    - Most specific order
* Dynamic Programming
  - Design Technique
  - Optimization --> bring exponential problems into polinomial runtimes
  - Minimum/Maximum of something --> Optimization
  - Exhaustive Search
    - It's bad because is exponential time; applying dp the time is polinomial
  - "careful brute force"
  - subproblems + reuse + guessing
  - Memomized dynamic programming
    - Saves the result of a computation into an auxiliary data structure.
    - "memo pad"
  - time = #subproblems * time/subproblem
    - time/subproblem --> it's usually Ã˜(1)
  - 5 "easy" steps
    - define subproblems : #subproblems
    - guess (part of the solution)
      - example: there exist a vertex before v -> number of choices for the guess
    - relate subproblems solutions
      - with recursion
      - recurring equation/relation
      - time/subproblems
    - recurre & memoize
      - or build a dp table bottom-up
        - DAG to check the dependencies to avoid cycles
    - Solve the original problem: goal.
** Fibonacci numbers
  - recursion relation:
    - F1 = F2 = 1
    - Fn= F(n-1) + F(n-2)
  - goal: compute Fn
*** naive
#+BEGIN_SRC ruby
def fib(n)
  return 1 [1,2].include?(n)
  fib(n-1) + fib(n-2)
#+END_SRC
**** Runtime
  - O(2^n)
    - I understand thi is exponential because at each level the computations are doubled. The function that describes that is exponential
  - Exponential: T(n) = T(n-1) + T(n-2) + O(1)
  - Ã˜(2^(n/2)) --> why?

*** memoized dp
#+BEGIN_SRC ruby
def memo_fib(n, dp)
  return dp[n] if dp[n]
  dp[n] = memo_fib(n-1) + memo_fib(n-2)
end

                (Fn)
       (Fn-1)         (Fn-2)
   (Fn-2) (Fn-3)  (Fn-3) (Fn-4)
#+END_SRC
  - memo_fib will have already calculated Fn-2 for the right subtree
  - memo_fib(k) only recurses the first time it's called, for all K
  - memoized calls cost O(1)
  - non-memoized calls are "n"
    - fib(1), fib(2), fib(3),....,fib(n)
  - non recursive work is O(1) --> O(n)
** Bottom-up Strategy
  - Exactly same computations
  - Topological sort of subproblem (left to right), dependency DAG
  - Can often save space
** Shortest Path
  - Guessing: don't know the answer but I'll guess and take the best one
  - Guest the last vertex --> solution state or goal
  - Recurring relationship
    - Æ’(s,v) = min { Æ’(s, u) + w(u, v) }; u belongs to the indegree of v
    - Æ’(s,s) = 0
  - subproblem dependencies should be "acyclic"
** Text Justification
  - goal: split text into "good" lines
  - text = list of words
  - badness(i,j):
    - (page width - total width)^3 -> discourage big gaps in the lines
    - infinity if don't fit
  - 5 "easy" steps
    - define subproblems: suffices words
    - guess: where to start 2nd line
      - #choices <= n - i == O(n)
    - recursion:
      - dp(i) = min { dp(j) + badness(i,j) for j in range(i+1, n+1) }
      - dp(n) = 0; base case
    - topological order: i = n,n-1,n-2,..,0
    - total time = n * n = O(n^2)
    - original problem or goal: dp(0)
** Parent Pointers
  - Remember which guess was best
  - Parent of i <- min/max of the value
  - 0 -> parent[0] -> parent[parent[0]] -> parent[parent[parent[0]]] -> ...
* Bit Manipulation
  - Operations over bits (bytes)
** How to represent numbers in a given base
  - 012 = 1*10^1 + 2*10^0
  - 101 = 1*2^2 + 0*2^1 + 1*2^0
** Addition
  - It's parallel to what's done for base 10, always carry the remainder of the base overflow
  - This operation cannot be applied for more than 2 numbers!
  - 0101 (5)
  - 0001 (1)
  - ====
  - 0110 (6)
** Multiplication
  - same to what's done for base 10.
  - if a number is multiplied by 2, just add a 0 at the end.
  - this happens whenever a number is multiplied by another number that represents its base
    - base (2)  10 * 10 = 100
      - 10 << 1
    - base (10) 40 * 10 = 400
** Negative numbers
  - the most significant bit is left to represent the sign of the number: 0 (+), 1 (-)
*** one's complement
  - compute the complement of the number: 100 --> 011
  - it has the problem of adding the number with different signs
  - example: 3 - 3 == 0
        - 0011 (3)
        - 1100 (-4)
        - ====
        - 1111 (-1)
*** two's complement
      - compute the complement of the number and adds 1 to the resulting number
      - adding 1 is needed to move the negative number to the correct place
      - example: 3 + (-3)
        - 0011 (3)
        - 1101 (-3)
        - ====
        - 0000 (0)
** Shifting Bits
  - The operation shift bits in a given direction (right, left)
*** (Logical|Arithmetic) Left Shift (<<)
    - 0110 << 1 results in 1100
    - shifting to the left is equivalent to multiplying the number by powers of 2.
      - 0110 << 1 == 0110 * 2^1
      - 0110 << 3 == 0110 * 2^3
  - This shifting is non-circular. This means that whatever value that was at the leftmost position would be lost:
    - 110 << 1 == 100
*** Logical Right Shift (>>>)
  - it's the converse to the left shift
    - It moves bits to the right
    - 001100 >>> 1 == 00011
  - Shifting to the right is equivalent to dividing by powers of 2
*** Arithmetic Right Shift (>>)
  - Same behavior that right shift, but instead of padding with zeros, it pads with the most significant bit
  - This is because the most significant bit is the sign bit (+ or -)
    - 1011 >> 2 = 1110
  - The sign is being preserved by using arithmetic right shift
*** Lost bits are gone
  - Shifting cannot reclaim "lost" bits
  - (1100 << 1) >>> 1 == 0100 != 1100
** BitMask and Mask
  - An integer can be used to store states:
    - 0101 -> first and third var are true, second and fourth are false.
  - This is a very efficient way of storing data
*** Bit Mask
  - It allows the following operations
    - Editing particular bits in a byte
    - Toggling particular bits in a byte
    - Checking if a particular bit values are present or not.
  - A bit mask is applied to our state "0101" and the resulting number indicates the bits of interest
    - AND -> extracts a subset of the bits in the state
    - OR  -> sets a subset of the bits in the state
    - XOR -> toggles a subset of the bits in the state.
  - Examples
    - mask:  1000
    - value: 0101
    - AND -> 0000
    - OR  -> 1101
    - XOR -> 1101
**** Addition
  - Add the jth object to the subset -> set the jth bit from 0 to 1
  - Use the bitwise OR operation
    - A = A | (1 << j)
  - Example
    - A =            100010 (34)
    - j = 3; 1 << 3  000100 (4)
    - OR             ======
    -                100110
**** Remove
  - Remove the jth object from the subset -> set the jth bit from 1 to 0
  - Use the bitwise AND operation
    - A = A & ~(1 << j)
  - Example
    - A =               101010
    - j = 1; ~(1 << 1)  111101
    - AND               ======
    -                   101000
**** Check
  - Check the jth object is in the subset
  - Use the bitwise AND operation
    - T = A & (1 << j)
  - Example
    - A =            101010
    - j = 3; 1 << 3  001000
    - AND            ======
    - T =            001000
    - T is not zero, thus the 3rd element is on.
**** Toggle
  - Check the jth object of the set
  - Use the bitwise XOR operation
    - A = A ^ (1 << j)
  - A =            101000
  - j = 2; 1 << 2  000100
  - XOR            ======
  -                101100
** Remove the least significant 1
 - n & (n - 1)
 - (11 & 10) --> 10 & 01 --> 00
** XOR same number
 - 8 ^ 8 == 0
** XOR number with 0
 - 3 ^ 0 == 3
[2,1,2]  --> resp = 0; resp = resp ^ 2; resp = resp ^ 1; resp = resp ^ 2
resp = 1
** Parity Check
  - If you XOR a bit string you can know whether it has an even or odd number of one's
    - 100 -> 1^0^0 == 1 -> odd
    - 101 -> 1^0^1 == 0 -> even
  - XOR is used to verify data sent over the wire. Suppose we sent 4 bytes
    - b0 -> 1011
    - b1 -> 0000
    - b2 -> 0101
    - b3 -> 1110
  - A checksum can be generated by picking the jth bit on every byte, let's say the 2 second bit (right to left)
  - After that, generate a 5th byte which is the result of XOR all the 2 second bits together, i.e.:
    - 0010
    - 0000
    - ---- XOR
    - 0010
    - 0000
    - ---- XOR
    - 0010
    - 0010
    - ---- XOR
    - 0000 --> send this 5th byte across the wire and use it as the checksum
** XOR is not available
  - x ^ y == (~x & y) | (x & ~y)
* System Design and Scalability
** how to approach questions
 - go broad first
   - do not focus too much on something in particular
 - use the whiteboard
 - acknowledge interviewer concerns
   - validate them --> write them down on the whiteboard
 - be careful about assumptions
 - state your assumptions explicitly!!
 - estimate when necessary
   - if you don't know the size of the data -> estimate
 - drive!
   - these questions are largely about the process rather than the ultimate design
** Design: step-by-step
*** Step 1: Scope the problem
  - Do not stop asking questions until you are clear about the problem you are trying to solve
  - Restate the requirements to the interviewer to confirm that requirements are correct
*** Step 2: Make Reasonable Assumptions
  - Infinite memory or 100 users per day are *unreasonable* assumptions
  - Guessing that the system will handle 1000 thousand of new URL is reasonable
  - Always confirm with your interviewer
*** Step 3: Draw the Major Components
  - Get up and go to the whiteboard
  - Draw major components (logical design?)
  - Verify the data flow
    - a user enters a new URL. Then what?
*** Step 4: Identify the Key Issues
  - Identify bottlenecks
  - What if a tinyURL becomes popular?
  - Go through some edge cases here
  - The interviewer might provide some guidance, use it!
*** Step 5: Redesign for the Key Issues
  - Change your design accordingly
  - Be open about any limitations in your design and acknowledge them.

** Algorithms that Scale: step-by-step
*** Step 1: Ask Questions
  - Do not stop asking question until you feel confident about it!
*** Step 2: Make Believe
  - Pretend that the data can all fit on one machine
  - Brute force it!
*** Step 3: Get Real
  - How much data can fit on one machine
  - can the data be split up?
*** Step 4: Solve Issues
  - solve issues you identified in step 2
  - issues might be eliminated by actually removing a particular problem entirely
  - or you can mitigate the issue
  - apply an iterative solution (revisit issues again)
** Key Concepts
*** Horizontal vs Vertical Scaling
  - Vertical scaling means increasing the resources of a specific node
    - Adding more memory
    - Adding more disk
  - Horizontal scaling means increasing the number of nodes
  - Vertical is easier than horizontal scaling, but it's limited.
*** Load Balancer
  - Allows the system to distribute the load uniformly across different boxes. This requires to have clone nodes that are running the same code.
  - This is also useful when deploying new code. The system does not become unavailable.
*** Database Denormalization and NoSQL
  - Joins in a relational system are expensive when the data grows bigger. For this reason, they are avoided.
  - Denormalization means adding redundant data into a table to speed up reads.
  - NoSQL by design do not support joins so that might force to redesign the data model
*** Database Partitioning (Sharding)
  - Splitting the data across multiple machines while ensuring there is a way to retrieve the data
**** Vertical Partitioning
  - This partitions by feature or "domain"
  - tables related to profiles, then the ones related to messages
**** Key-Based (hash-based) Partitioning
  - This uses some part of the data (the ID) to do the partitioning. Allocate N servers and then the hashing function could do mod(id,n).
    - the problem with this strategy is that fails when more servers are added
**** Directory-Based Partitioning
  - A table is maintained to keep info where the data is stored
    - the problem with this strategy are:
      - single point of failure
      - constant access to this table impacts performance.
*** Caching
  - Typically sits between your application layer and your data store.
  - Query and its results are cached.
*** Asynchronous Processing & Queues
  - Slow operations should be computed ideally asynchronously
  - Pre-compute part of the website and refresh the cache
*** Networking Metrics
  - Bandwidth: maximum amount of data that can be transferred per unit of time
  - Throughput: Actual amount of data transported/transferred
  - Latency: How long it takes data to from end to end
*** MapReduce
  - It's use to process large amount of data
  - Maps: emits <key, value>
  - Reduce: receives <key, value> and emits <key, value2>
  - This allows to process data in parallel
** Considerations
  - Failures: any part of the system can fail. Need to plan for them (cut the wire)
  - Availability: is a function of the percentage of time the system is operational
  - Reliability: is a function of the probability that the system is operational for a certain unit of time
  - Read-Heavy: you might want to cache
  - Write-Heavy: you might want to queue writes
  - Security
* Databases
** Denormalized vs Normalized Databases
  - normalized databases are designed to minimize redundancy
  - denormalized databases are designed to make read operations faster.
** Small Database Design
*** Step 1: Handle Ambiguity
  - Keep asking questions until the requirements are clear
  - Be sure that you have covered a couple of edge cases
*** Step 2: Define the core objects
  - This will lead to define entities (tables)
*** Step 3: Analyze Relationships
  - How do the entities interact with each other
  - This is time to start defining fk's in the tables
  - You will define more tables in this process!! (n to m relationships)
*** Step 4: Investigate Actions
  - Walk through the common actions that will be taken and understand how to store and retrieve the relevant data.
** Large Database Design
  - joins are your enemy! (most of the time)
  - Denormalize the data somehow to improve performance (i.e.: reduce latency)
    - duplicate data in tables: increase redundancy
    - create new tables if necessary.
** Exercises
*** 14.1 Multiple Apartments
#+BEGIN_SRC sql
SELECT t.id, t.name
FROM tenants t
     INNER JOIN aptTenants at ON (at.tenantID = t.id)
GROUP BY t.id, t.name
HAVING COUNT(1) > 1
#+END_SRC

*** 14.2 Open Requests
#+BEGIN_SRC sql
SELECT b.name, COUNT(1)
FROM buildings b
     INNER JOIN apartments a ON (a.b_id = b.id)
     LEFT JOIN requests r ON (r.a_id = a.id)
WHERE
     r.status = 'open'
GROUP BY b.id, b.name
#+END_SRC

*** 14.3 Close All Requests
#+BEGIN_SRC sql
UPDATE requests r
SET r.status = 'close'
FROM buildings b
     INNER JOIN apartments a ON (a.b_id = b.id)
     INNER JOIN requests r ON (r.a_id = a.id)
WHERE
     r.status = 'open'
     AND b.id = 11
#+END_SRC

*** 14.4 Joins
  - natural join: uses columns that are equal to restrict the cartesian product
  - inner join: uses a given number of columns to restrict the cartesian product
  - left join: keep left rows in the resulting set even if there is no match for them
  - right join: keep right rows in the resulting set even if there is no match for them
  - full join: keep left and right rows in the resulting set even if there is no match form them
*** 14.5 Denormalization
  - It's the process of adding redundant information into different tables.
  - Pro: read operations are faster because joins are less used
  - Cons: Data is duplicated. If some data change in the "source" table, then a process to keep the duplicated values in sync is needed.
*** 14.7 Design a grade database
  - |student|-1-N-|grade|
#+BEGIN_SRC sql
SELECT TOP 10 PERCENT s.id, AVG(g.grade) avg
FROM grade g
     INNER JOIN student s ON (g.s_id = s.id)
GROUP BY s.id
ORDER BY avg DESC
#+END_SRC
* Threads and Locks
  - Understanding of dead locks is important.
** Threads in Java
  - An object of the class java.lang.Thread controls every thread
  - Standalone app is run in a user thread. The main method is executed in the context of this thread.
  - Threads can be implemented in two ways:
    - An implementation of the java.lang.Runnable interface
    - A subclass of the java.lang.Thread class
  - InterruptedException is defined to stop thread execution
    - it handles signals/interrupts
*** Extending vs Implementing
  - Implementing Runnable is preferable to extending because:
    - Class can only inherit from one class (multi-inheritance is not supported)
    - Class might only be Runnable and it will be forced to be a subclass of Thread
** Synchronization and Locks
  - Threads within a given process share the same memory space
  - Issues when two threads modify the same resource
  - Java provides synchronization methods in order to control access to share resources
    - synchronized
    - lock
*** Synchronization
  - This is used to control method executions
    #+BEGIN_SRC java
    public class Account{
      public synchronized int withdraw(int money){
        ..
      }
    }
    #+END_SRC
  - Two threads holding the same instance of Account cannot call withdraw concurrently
  - Two threads holding two different instances of Account can call withdraw concurrently
  - The thread acquires the lock at the object level.
**** Static Synchronization
  - The thread acquires the lock at the class level.
  - Two different threads cannot run 2 different static synchronized methods of the same class concurrently
**** Synchronized Blocks
  #+BEGIN_SRC java
  synchronized(this || Class.getClass()){
    ..
  }
  #+END_SRC
  - Same idea of thread acquiring a lock at the instance or class level
** Locks (monitors)
  - Used to lock the access to a share resource. This happens when multiple threads want to access a resource.

** Deadlocks and Deadlocks Prevention
 - one thread is waiting for an object lock that another thread holds, and this second thread is waiting for an object lock that the first thread holds.
 - Conditions for a deadlock to occur:
   - mutual exclusion: only one process can access a resource of a given time. A deadlock could also occur if a resource has limited quantity.
   - hold and wait: Processes already holding a resource can request additional resources without relinquishing their current resources.
   - no preemption: One process cannot forcibly remove another process' resource.
   - Circular wait: two or more processes form a circular chain where each process is waiting on another resource in the chain
     - this can be avoid by running a deadlock prevention algorithm.
* CAP Theorem
  - Any distributed system has the following core attributes:
    - Consistency
    - Availability
    - Partition Tolerance
  - This theorem states that a distributed system can only have 2 core attributes:
    - CA: Consistency and Available; this should be dismissed because it does not account for failures (P)
    - CP: Consistency and Partition Tolerance
    - AP: Available and Partition Tolerance
  - Factors like latency or throughput can influence which letter to use: "A" or "C"
** Consistency
  - A system is consistent if an update is applied to all relevant nodes at the some logical time
    - A standard database replication is not strongly consistent.
  - All the nodes see the same information at a given point of time after performing an update.
  - An update is "committed" after all the nodes agreed on it.
** Availability
  - The system is able to reply a given query. If I don't get a response then the system is not available.
  - There is a catch here. This does not apply if a node is dead (if a node is dead, then it cannot give wrong results)
** Partition Tolerance
  - System can keep on working (and contain useful info) even when parts of it can no longer communicate together
  - A network partitions aren't limited to dropped packets. A crashed server can be thought of as a network partition.
** Example (http://learnyousomeerlang.com/distribunomicon#my-other-cap-is-a-theorem)
  - Two groups
    - Chainsaw: Bill, Zoey
    - Crossbow: Rick, Daryl
  - Bill and Zoey will meet Rick and Daryl on Friday before dawn
  - A dense flag cut the communications between Chainsaw and Crossbow camps
  - Bill and Zoey got delayed and they requested to its camp (Chainsaw) to change the time of the meeting to later in the day
  - Chainsaw cannot communicate this due to a dense fog.
*** Camps Operating Under CP
  - Setting a new meeting is rejected.
  - CP is all about stopping *modifications* to the data so it remains consistent.
  - Survivors can still read from the system.
*** Camps Operating Under AP
  - Setting a new meeting is accepted.
  - Each camp now have different versions of the data
  - Meeting of Friday
    - Chainsaw -> Friday Night
    - Crossbow -> Friday before dawn
** Strategies for Resolving Conflicts
  - The split is gone (fog) and the systems can communicate now.
*** CP Approach
  - Nothing to do. Data was not changed at all
*** AP Approach
  - Since this approach is more flexible, different strategies can be employed:
    - Last Write Wins: whatever last update is the one that's kept
    - A Winner can be picked randomly
    - Relative clocks: Lamport clocks or Vector clocks
    - The application is in charge of solving the conflicts (similar to what happen with GIT, SVN)
** Quorum Systems
  - This type of systems can be used to be more flexible regarding Consistency and Availability
  - Suppose there are "n" nodes and the system require "n" of them to agree on changing some data
  - A system with low consistency requirement can allow 15% of the nodes to agree on changing data
  - A system with higher consistency requirement can allow 75% of the nodes to agree on changing data
  - By changing m to n then the system is fully consistent: CP
  - By changing m to 1 then the system is fully available: AP
  - The strategy can be mixed depending upon the type of operations:
    - user logging (m = 1)
    - withdraw money (m = 75)
** Yield and Harvest
  - yield: percent of requests answered successfully.
  - harvest: percent of required data actually included in the responses.
** Resources
 - http://learnyousomeerlang.com/distribunomicon#my-other-cap-is-a-theorem
 - https://codahale.com/you-cant-sacrifice-partition-tolerance/
* Greedy Algorithms
** Resources
  - https://www.youtube.com/watch?v=EcT-Jt5WStw
  - 
  - https://www.youtube.com/watch?v=-QcPo_DWJk4
* Exercises
** Array and String
*** Is Unique
    Implement an algorithm to determine if a string has
    all unique  characters.  What  if you  cannot use  additional data
    structures?
    1. This  solution is ~O(len(string) +  len(letters.values))~, thus
       ~O(n)~.   I  am  making  the assumption  that  hash  access  is
       constant.
#+BEGIN_SRC ruby
  def is_unique?(string)
    letters = Hash.new(0)
    string.each_char do |char|
      letters[char] += 1
    end
    letters.values.select{|counter| counter > 1}.empty?
  end
#+END_SRC

    2. This solution is ~O(n * log(n) + n)~, thus ~O(n * log n)~.  I am
       assuming that I cannot use an additional data structure.
#+BEGIN_SRC ruby
  def is_unique?(string)
    sorted_string = string.split(//).sort
    next_index = 1
    result = true
    sorted_string[0..-2].each do |char|
      if char == sorted_string[next_index]
	result = false
	break
      end
      next_index += 1
    end
    result
  end
#+END_SRC

*** Check permutation
    Given two strings write a method to decide if one is a permutation of the other.
    #+BEGIN_SRC ruby
    def permutation(s1, s2)
      new_s1 = s1.split(//)
      new_s2 = s2.split(//)
      store = {}
      new_s2.each do |char|
        store[char] = true
      end

      result = true
      new_s1.each do |char|
        if !store.has_key?(char)
          result = false
	  break
	end
      end
      result
    end
    #+END_SRC

*** URLify
    The solution is ~O(n + n)~, this ~O(n)~.

    #+BEGIN_SRC ruby
def urilify(string_array, size)
  spaces_index = []
  string_array[0..(size - 1)].each_with_index do |char, index|
    spaces_index << index if char == " "
  end

  current_index = spaces_index.count * 2 + size - 1
  string_index = size - 1

  while(current_index >= 0) do
    if spaces_index.include?(string_index)
      string_array[current_index] = "0"
      string_array[current_index - 1] = "2"
      string_array[current_index - 2] = "%"
      current_index -= 3
    else
      string_array[current_index] = string_array[string_index]
      current_index -= 1
    end
    string_index -= 1
  end
  string_array
end
    #+END_SRC

*** Palindrome  Permutation
    Given  a  string,  check  if  any
    permutation of  it is a palindrome.   The solution I came  up is a
    recursive  solution,  and I'm  pretty  sure  that is  exponential.
    However I don't know how to prove that.
    #+BEGIN_SRC ruby
def remaining_array(init, array)
  size = array.count
  size.times.map do |index|
    i = (init + index) % size
    array[i]
  end[1..-1]
end


def permutation(array)
  return array if array.empty?
  return [array] if array.count == 1
  results = []
  array.each_with_index do |e, index|
    permutation(remaining_array(index, array)).each do |a|
      results << [e].concat(a)
    end
  end
  results
end

def palindrome?(array)
  left_index = 0
  right_index = -1
  flag = true
  limit = (array.size/2.to_f).ceil
  array.size.times do |index|
    if right_index.abs > limit
      break
    end

    if array[index] != array[right_index] && (!array[index].blank? && !array[right_index].blank?)
      flag = false
      break
    end
    right_index -= 1
  end
  flag
end

def is_palindrome(s1)
  array = s1.split(//)
  permutation(array).select{|a| palindrome?(a) == true}.any?
end
    #+END_SRC

*** One Away
    Given two strings, write a function to check if they are one edit (or zero edits) away.
    #+BEGIN_SRC ruby
def is_one_away?(s1, s2)
  longest, shortest = s1.size > s2.size ? [s1, s2] : [s2, s1]
  counter = 0
  shortest_index = 0
  longest.split(//).each_with_index do |char, index|
    if char == shortest[shortest_index]
      shortest_index += 1
      next
    end

    if longest[index+1] == shortest[shortest_index]
      counter += 1
    elsif longest[index+1] == shortest[shortest_index+1]
      counter += 1
      shortest_index += 1
    end
  end
  counter <= 1 ? true : false
end

is_one_away?("pale", "ple") == true
is_one_away?("pales", "pale") == true
is_one_away?("pale", "bale") == true
is_one_away?("pale", "bake") == false
    #+END_SRC

*** String Compression
    aabcccccaaa `->` a2b1c5a3
    #+BEGIN_SRC ruby
def compress(string)
  normalized_string = string.split(//)
  repetitions = 0
  previous = normalized_string[0]
  new_string = ""
  normalized_string.each do |char|
    if (char == previous)
      repetitions += 1
    else
      new_string += "#{previous}#{repetitions}"
      previous = char
      repetitions = 1
    end
  end
  if normalized_string[-1] == previous
    new_string += "#{previous}#{repetitions}"
  end
  new_string
end
    #+END_SRC

*** Zero Matrix
    Given a MxN matrix, write an algorithm such that
    if an element is 0, its entire row and columns are set to 0.
    #+BEGIN_SRC ruby
def zero_matrix(matrix, row_count, column_count)
  rows = []
  columns = []
  matrix.each_with_index do |row, row_index|
    row.each_with_index do |element, column_index|
      if element == 0
        rows << row_index
        columns << column_index
      end
    end
  end
  rows.uniq.each do |row_index|
    matrix[row_index] = column_count.times.map{|c| 0}
  end
  columns.uniq.each do |column_index|
    matrix.each do |row|
      row[column_index] = 0
    end
  end
  matrix
end

zero_matrix([[1, 2], [3, 4], [5, 0]], 3, 2) == [[1, 0], [3, 0], [0, 0]]
    #+END_SRC

  - [X] *String Rotation*
    "waterbottle" is a rotation of "erbottlewat"
    #+BEGIN_SRC ruby
    def is_rotation(s1, s2)
      "#{s2}#{s2}".include?(s1)
    end

    is_rotation("waterbottle", "erbottlewat") == true
    #+END_SRC

*** Reverse a string
#+BEGIN_SRC ruby
def reverse(str, i, j)
  while j > i
    tmp
 = str[i]
    str[i] = str[j]
    str[j] = tmp
    i = i + 1
    j = j - 1
  end
  str
end
#+END_SRC
*** Reverse words
#+BEGIN_SRC ruby
def reverse_words(str)
  reverse(str, 0, str.size - 1).split(" ").map do |word|
    reverse(word, 0, word.size - 1)
  end.join(" ")
end
#+END_SRC
** Linked List
*** Length
#+BEGIN_SRC ruby
class LinkedList
  def length
    current = self.head
    counter = 0
    while current != nil
      counter = counter + 1
      current = current.next
    end
    counter
  end
end
#+END_SRC
*** Search an Element
#+BEGIN_SRC ruby
class LinkedList
  def search_iterative(key)
    current = self.head
    found = false
    while current != nil
      if key == current.data
        found = true
        break
      end
      current = current.next
    end
    found
  end

  def search_recursive(key, current=self.head)
    if current == nil
      false
    else
       if key == current.data
         true
       else
         search_recursive(key, current.next)
       end
    end
  end
end
#+END_SRC
*** DeleteFirst
#+BEGIN_SRC ruby
class LinkedList
  def delete_first
    return if self.head.nil?

    head = self.head
    new_head = head.next
    self.head = new_head
    head = nil
  end
end
#+END_SRC

*** Swap Nodes
#+BEGIN_SRC ruby
class LinkedList
  def swap(x, y)
    #Cases:
    #1. x or y can be head
    #2. x and y can be adjacents nodes
    #3. x and y are not adjacents nodes
    current = self.head
    prevX = currentX = prevY = currentY = nil
    while current != nil
      if current.data == x
        currentX = current
      elsif current.data == y
        currentY = current
      end
      if currentX.nil?
        prevX = current
      end
      if currentY.nil?
        prevY = current
      end
      break if [currentX, currentY].compact.size == 2
      current = current.next
    end
    return if [currentX, currentY].compact.size != 2

    newNextY = currentX.next
    newNextX = currentY.next
    if currentY == newNextY
      currentY.next = currentX
    else
      currentY.next = newNextY
    end
    currentX.next = newNextX
    if prevX.nil?
      self.head = currentY
    else
      prevX.next = currentY
    end
    if prevY != currentX
      prevY.next = currentX
    end
  end
end
#+END_SRC
*** Get nth element
#+BEGIN_SRC ruby
class LinkedList
  def nth(key_index)
    index = 1
    current = self.head
    while current != nil
      if index == key_index
        break
      else
        index = index + 1
        current = current.next
      end
    end
    current.data if current
  end
end
#+END_SRC
*** (16) Reverse
#+BEGIN_SRC ruby
class LinkedList
  def reverse
    current = self.head
    next_node = nil
    while current != nil
      prev = current.next
      current.next = next_node
      next_node = current
      current = prev
      prev = prev.next if prev
    end
    self.head = next_node
  end
end
#+END_SRC
*** (17) Detect Loop
**** Modifiying Node
#+BEGIN_SRC ruby
class Node
  attr_accessor :visited
end

class LinkedList
  def loop?
    loop = false
    current = self.head
    while current != nil
      if !current.visited
        current.visited = true
      else
        loop = true
        break
      end
      current = current.next
    end
    loop
  end
end
#+END_SRC
**** Using Hash
#+BEGIN_SRC ruby
class LinkedList
  def loop_hash?
    loop = false
    node_hash = {}
    current = self.head
    while current != nil
      if node_hash.has_key?(current)
        loop = true
        break
      else
        node_hash[current] = true
      end
      current = current.next
    end
    loop
  end
end
#+END_SRC
**** Using Floyd's Cycle-Finding Algorithm
#+BEGIN_SRC ruby
class LinkedList
  def loop_floyd?
    loop = false
    current = self.head
    slow = current
    fast = current
    while current != nil and slow != nil and fast != nil
      slow = current.next
      fast = current.next.next
      if slow == fast
        loop = true
        break
      end
      current = current.next
    end
    loop
  end
end
#+END_SRC
*** (18) Merge Two Sorted Lists
#+BEGIN_SRC ruby
class LinkedList
  #HINT: This method builds new nodes.
  #TODO: Implement a method that reuses nodes.
  def merge_sorted(other)
    new_list = LinkedList.new
    current_other = other.head
    current_this = self.head
    while current_other != nil and current_this != nil
      if current_this.data < current_other.data
        new_list.append(current_this.data)
        current_this = current_this.next
      else
        new_list.append(current_other.data)
        current_other = current_other.next
      end
    end
    if current_other
      while current_other != nil
        new_list.append(current_other.data)
        current_other = current_other.next
      end
    end
    if current_this
      while current_this != nil
        new_list.append(current_this.data)
        current_this = current_this.next
      end
    end
    new_list
  end
end
#+END_SRC
*** (20) Insert value in a sorted way
start: 9:57
end: 10:09
#+BEGIN_SRC ruby
class LinkedList
  def insert_ordered(key)
    node = Node.new(key)
    prev = nil
    current = self.head
    while current != nil
      if current.data > key
        if current == self.head
          node.next = current
          self.head = node
        else
          prev.next = node
          node.next = current
        end
        break
      end
      prev = current
      current = current.next
    end
    if current.nil? and prev.nil?
      self.head = node
    elsif current.nil? and !prev.nil?
      prev.next = node
    end
  end
end
#+END_SRC 
*** (21) Delete a given node
start: 10:09
end: 10:26
#+BEGIN_SRC ruby
class LinkedList
  def delete_ordered(node)
    prev = nil
    current = self.head
    while current != nil
      if current == node
        if current == self.head
          self.head = current.next
        else
          prev.next = current.next
        end
        current = nil
        break
      end
      prev = current
      current = current.next
    end
  end
end
#+END_SRC
#+BEGIN_SRC ruby
#TODO: Talk to Manoj about this
class LinkedList
  def delete_node(node)
    if node.next.nil?
      node = nil
    else
      node.data = node.next.data
      node.next = node.next.next
    end
  end
end
#+END_SRC
*** (22) Check if list is palindrome
start: 10:27
end: 10:35
#+BEGIN_SRC ruby
class LinkedList
  def palindrome?
    stack = []
    current = self.head
    while current != nil
      stack.push current.data
      current = current.next
    end
    return false if stack.empty?

    current = self.head
    palindrome = true
    while !stack.empty?
      value = stack.pop
      if current.data != value
        palindrome = false
        break
      end
      current = current.next
    end
    palindrome
  end
end
#+END_SRC

start: 10:40
end: 11:33
#+BEGIN_SRC ruby
class LinkedList
  def size
    current = self.head
    counter = 0
    while current != nil
      counter = counter + 1
      current = current.next
    end
    counter
  end

  def reverse_from(key_index)
    prev = nil
    next_node = nil
    current = self.head
    index = 0
    while index != key_index - 1
      index = index + 1
      current = current.next
    end
    head = current
    prev = current
    current = current.next
    while current != nil
      next_node = current.next
      if head == prev
        current.next = nil
      else
        current.next = prev
      end
      prev = current
      current = next_node
    end
    head.next = prev
  end

  def palindrome_wo_stack?
    return false if size < 2

    mid = (size/2.to_f).ceil
    reverse_from mid
    second_current = self.head
    index = 0
    while index != mid
      index
= index + 1
      second_current = second_current.next
    end
    palindrome = true
    current = self.head
    while second_current != nil
      if current.data != second_current.data
        palindrome = false
        break
      end
      second_current = second_current.next
      current = current.next
    end
    palindrome
  end
end
#+END_SRC

*** (23) Intersection Point of two lists
start: 11:35
end: 11:44
#+BEGIN_SRC ruby
#TODO: Discuss about a better way of implementing this
class LinkedList
  def intersection_point(other)
    nodes = {}
    current = self.head
    while current != nil
      nodes[current] = true
      current = current.next
    end
    current = other.head
    while current != nil
      if nodes.has_key?(current)
        break
      end
      nodes[current] = true
      current = current.next
    end
    current
  end
end
#+END_SRC
*** (24) Print Reverse
start: 12:25
end: 12:28
#+BEGIN_SRC ruby
class LinkedList
  def print_reverse(current = self.head)
    if current != nil
      print_reverse(current.next)
      puts current.data
    end
  end
end
#+END_SRC
*** (25) Remove duplicates sorted lists
start: 12:29
end: 12:40
#+BEGIN_SRC ruby
class LinkedList
  def remove_duplicates_sorted
    current = self.head
    next_node = nil
    while current != nil and current.next != nil
      next_node = current.next
      if current.data == next_node.data
        current.next = next_node.next
        next_node = nil
      else
        current = current.next
      end
    end
  end
end
#+END_SRC
*** (26) Remove duplicates unsorted lists
start: 12:42
end: 12:50
#+BEGIN_SRC ruby
class LinkedList
  def remove_duplicates_unsorted
    prev = nil
    current = self.head
    values = {}
    while current != nil
      next_node = current.next
      if values.has_key?(current.data)
        prev.next = current.next
      else
        values[current.data] = true
        prev = current
      end
      current = prev.next
    end
  end
end
#+END_SRC
*** (27) Pairwise swap elements
start: 3:46
end: 4:11
#+BEGIN_SRC ruby
class LinkedList
  def pairwise
    prev = nil
    next_node = nil
    current = self.head
    while current != nil and current.next != nil
      next_node = current.next
      current.next = next_node.next
      next_node.next = current
      if prev.nil?
        self.head = next_node
      else
        prev.next = next_node
      end
      prev = current
      current = current.next
    end
  end
end
#+END_SRC
*** (28) Practice questions about recursion
  - 1 -> prints the list in reverse order
  - 2 -> prints the elements of the list that are in an even position; it prints the elements twice.
*** (29) Move last element to the front
start: 4:19
end: 4:23
#+BEGIN_SRC ruby
class LinkedList
  def move_last_ele_to_the_front
    return if self.head.nil? || self.head.next.nil?

    prev = nil
    current = self.head
    while current.next != nil
      prev = current
      current = current.next
    end
    prev.next = nil
    current.next = self.head
    self.head = current
  end
end
#+END_SRC
*** (30) Intersection set of two lists
start: 4:24
end: 4:41
#+BEGIN_SRC ruby
class LinkedList
  def intersection_set(other)
    new_list = LinkedList.new
    first = self.head
    second = other.head
    while first != nil and second != nil
      if first.data == second.data
        new_list.append(first.data)
        first = first.next
        second = second.next
      elsif first.data < second.data
        first = first.next
      else
        second = second.next
      end
    end
    new_list
  end
end
#+END_SRC
*** (31) Delete Alternate Nodes
start: 4:44
end: 4:50
#+BEGIN_SRC ruby
class LinkedList
  def alternate_nodes
    current = self.head
    while current != nil and current.next != nil
      tmp = current.next
      current.next = tmp.next
      tmp = nil
      current = current.next
    end
  end
end
#+END_SRC
*** (32) Alternating Split
start: 4:50
end: 5:00
#+BEGIN_SRC ruby
class LinkedList
  def alternating_split
    first_list = LinkedList.new
    second_list = LinkedList.new
    if self.head.next == nil
      return [first_list.append(self.head), second_list]
    end

    first = self.head
    second = self.head.next
    while second != nil
      first_list.append(first.data)
      second_list.append(second.data)
      first = second.next
      second = first.next
    end
    if first
      first_list.append(first.data)
    end
    [first_list, second_list]
  end
end
#+END_SRC
*** (33) Identical Lists
start: 5:01
end: 5:06
#+BEGIN_SRC ruby
class LinkedList
  def identical?(other)
    identical = true
    first = self.head
    second = other.head
    while first != nil and second != nil
      if first.data != second.data
        identical = false
        break
      end
      first = first.next
      second = second.next
    end
    first.nil? and second.nil? ? identical : !identical
  end
end
#+END_SRC
*** (34) Merge Sort for Linked Lists
start: 5:11
end: 5:39
#+BEGIN_SRC ruby
class LinkedList
  de
f mid_node(first, last)
    slower = first
    faster = first
    while faster != last and faster.next != last
      slower = slower.next
      faster = faster.next.next
    end
    slower
  end

  def merge_sort(first, last)
    return LinkedList.new(Node.new(first.data)) if first == last

    middle_point = mid_node(first, last)
    left = merge_sort(first, middle_point).head
    right = merge_sort(middle_point.next, last).head
    new_list = LinkedList.new
    while left != nil or right != nil
      if left and right
        if left.data < right.data
          new_list.append(left.data)
          left = left.next
        else
          new_list.append(right.data)
          right = right.next
        end
      elsif left
        new_list.append(left.data)
        left = left.next
      elsif right
        new_list.append(right.data)
        right = right.next
      end
    end
    new_list
  end
end
#+END_SRC
*** (35) Reverse Linked List in groups of given size
start: 5:41
end: 7:05
#+BEGIN_SRC ruby
class LinkedList
  def reverse(prev_node, start_node, next_to_end_node)
    prev = prev_node
    current = start_node
    while current != next_to_end_node
      next_node = current.next
      current.next = prev
      prev = current
      current = next_node
    end
    start_node.next = next_to_end_node
  end

class LinkedList
  def reverse_groups(group_size)
    start_node = self.head
    end_node = start_node
    next_node = nil
    prev = nil
    while start_node != nil && start_node.next != nil
      current_size = 1
      while current_size != group_size and end_node != nil
        end_node = end_node.next
        current_size = current_size + 1
      end
      break if end_node.nil?

      next_node = end_node.next

      tmp_current = start_node
      tmp_next_node = nil
      tmp_prev = prev
      while tmp_current != next_node
        tmp_next_node = tmp_current.next
        tmp_current.next = tmp_prev
        tmp_prev = tmp_current
        tmp_current = tmp_next_node
      end
      start_node.next = next_node

      if prev.nil?
        self.head = end_node
      else
         prev.next = end_node
      end
      prev = start_node
      start_node = next_node
      end_node = next_node
    end
  end
end
#+END_SRC
*** 51
*** 69
*** 15
*** 29
*** 15
*** 60
** Stack
*** (3) Evaluate a postfix expresion
#+BEGIN_SRC ruby
#2 3 1 * + 9 -
def eval_postfix(postfix_str)
  stack = []
  postfix_str.split(" ").each do |char|
     if char =~ /[0-9]+/
       stack.push char.to_i
     else
       second = stack.pop
       first = stack.pop
       stack.push first.public_send(char, second)
     end
  end
  stack.pop
end
#+END_SRC
*** (4) Reverse a string
#+BEGIN_SRC ruby
def reverse(str)
  stack = []
  str.split("").each do |char|
    stack.push char
  end
  acc = ""
  while !stack.empty?
    acc = acc + stack.pop
  end
  acc
end
#+END_SRC
*** (5) Implement Two stacks in an Array
start: 7:00
end: 7:22
#+BEGIN_SRC ruby
class TwoStacks
  attr_accessor :arr, :indexes, :max_size
  def initialize(max_size=50)
    self.arr = Array.new(max_size)
    self.indexes = [-1, max_size]
    self.max_size = max_size
  end

  def _push(ele, left, right, op1, op2)
    return if self.indexes[left] == self.indexes[right].send(op1, 1)
    self.indexes[left] = self.indexes[left].send(op2, 1)
    self.arr[self.indexes[left]] = ele
  end

  def push1(ele)
    _push(ele, 0, 1, '-', '+')
  end

  def push2(ele)
    _push(ele, 1, 0, '+', '-')
  end

  def _pop(index, lower_boundary)
    return if self.indexes[index] == lower_boundary
    ele = self.arr[self.indexes[index]]
    self.arr[self.indexes[index]] = nil
    self.indexes[index] = self.indexes[index] - 1
    ele
  end

  def pop1
    _pop(0, -1)
  end

  def pop2
    _pop(1, self.max_size)
  end
end
#+END_SRC
*** (6) Balanced Parentheses
start: 7:47
end: 7:54
#+BEGIN_SRC ruby
def balanced_parentheses?(str)
  stack = []
  str.split("").each do |char|
    case char
      when "]"
        top = stack.pop
        break if top != "["
      when ")"
        top = stack.pop
        break if top != "("
      when "}"
        top = stack.pop
        break if top != "{"
      else
        stack.push(char)
    end
  end
  stack.empty?
end
#+END_SRC
*** (7) Next Greater Element
start: 7:55
end: 9:32
#+BEGIN_SRC ruby
def next_greater2(numbers)
  stack = []
  numbers.each do |number|
    if stack.empty?
      stack.push [number, -1]
    else
      top_ele, top_greater = stack[-1]
      if number > top_ele
        aux_stack = []
        loop do
          ele, greater = stack[-1]
          break if greater != -1 or ele > number
          ele, greater = stack.pop
          aux_stack.push [ele, number]
        end
        while !aux_stack.empty?
          stack.push aux_stack.pop
        end
      end
      stack.push [number, -1]
    end
  end
  while !stack.empty?
    ele, greater = stack.pop
    puts "#{ele}, #{greater}"
  end
end
#+END_SRC
*** (8) Reverse a stack using recursion
start: 4:38 5:02
end: 
#+BEGIN_SRC ruby
def reverse_stack(stack, result=[])
  if stack.empty?
    return result
  end
  result.push stack.pop
  reverse_stack(stack, result)
end
#+END_SRC
*** (9) Sort a stack using recursion
start: 5:03
end: 5:30
#+BEGIN_SRC ruby
def main(stack)
  repeat(stack.size, 0, stack)
end

def repeat(times, index, sorted_stack)
  return sorted_stack if times == index
  sorted_stack = sort_stack_recursion(sorted_stack)
  repeat(times, index+1, sorted_stack)
end

def sort_stack_recursion(stack)
  return stack if stack.size == 1
  tmp = stack.pop
  sorted_stack = sort_stack_recursion(stack)
  if tmp < sorted_stack[-1]
    ele = sorted_stack.pop
    sorted_stack.push tmp
    sorted_stack.push ele
  else
    sorted_stack.push tmp
  end
  sorted_stack
end
#+END_SRC
*** (10) Stock Span Problem
start: 5:32
end: 5:46
https://www.youtube.com/watch?v=LvQzYMXEANs
#+BEGIN_SRC ruby
def WRONG_stock_span(prices)
  stack = [prices.first]
  results = [1]
  index = 1
  prices[1..-1].each do |price|
    tmp_stack = []
    counter = 1
    while !stack.empty?
      ele = stack.pop
      if price >= ele
        counter = counter + 1
      end
      tmp_stack.push ele
    end
    while !tmp_stack.empty?
      stack.push tmp_stack.pop
    end
    results[index] = counter
    index = index + 1
    stack.push price
  end
  results
end

def stock_span(prices)
  stack = [0]
  spans = [1]
  index = 1
  max = prices.size
  while index != max
    while !stack.empty? && prices[index] > prices[stack[-1]]
      stack.pop
    end
    if stack.empty?
      h = -1
    else
      h = stack[-1]
    end
    spans[index] = index - h
    stack.push index
    index = index + 1
  end
  spans
end
#+END_SRC
*** (11) Design and Implement Special Stack
start: 7:11
end: 7:29
#+BEGIN_SRC ruby
class SpecialStack
  attr_accessor :elements, :mins, :capacity, :current_size
  def initialize(capacity)
    self.elements = []
    self.mins = []
    self.capacity = capacity
    self.current_size = 0
  end

  def push(ele)
    return if isFull
    self.elements.push ele
    if self.mins.empty?
      self.mins.push ele
    elsif ele < self.mins[-1]
      self.mins.push ele
    end
    self.current_size += 1
  end

  def pop
    return if isEmpty
    ele = self.elements.pop
    if ele == self.mins[-1]
      self.mins.pop
    end
    ele
  end

  def isEmpty
    self.current_size == 0
  end

  def isFull
   self.capacity == self.current_size
  end

  def getMin
    self.mins[-1]
  end
end
#+END_SRC
*** (12) Implement a Stack by using queue
start: 7:30
end:
#+BEGIN_SRC ruby
class MyStack
  attr_accessor :front, :bottom
  def initialize
    self.front = Queue.new
    self.bottom = Queue.new
  end

  def push(ele)
    if self.front.empty?
      self.front.enq ele
    else
      front = self.front.pop
      self.bottom.enq front
      self.front.enq ele
    end
  end

  def pop
    if self.front.size == 1
      self.front.pop
    elsif self.front.empty?
      while self.bottom.size > 1
        self.front.enq self.bottom.pop
      end
      self.bottom.pop
    end
  end
end
#+END_SRC
*** (13) Stack with operations in the middle
start: 5:20
end: 5:54
start_2: 8:40
end_2: 9:37
#+BEGIN_SRC ruby
#array cannot be used
class WRONG_ArrayStackMiddle
  attr_accessor :array, :size
  def initialize
    self.array = []
    self.size = 0
  end

  def push(ele)
    self.array.push ele
    self.size = self.size + 1
  end

  def pop()
    if !self.array.empty?
      while self.array[-1] ! nil
        self.array.pop
      end
      self.size = self.size - 1
      self.array.pop
    end
  end

  def middle()
    (self.size / 2.to_f).floor
  end

  def find_middle()
    self.array[self.middle]
  end

  def delete_middle()
    self.array[self.middle] = nil
  end
end

class Node
  attr_accessor :data, :next, :prev
  def initialize(data)
    self.data = data
  end
end

class DoublyLinkedListStack
  attr_accessor :head, :middle_node, :size, :middle_index
  def initialize
    self.head = self.middle_node = nil
    self.size = self.middle_index = 0
  end

  def push(ele)
    node = Node.new(ele)
    self.size = self.size + 1
    if !self.head.nil?
      node.next = self.head
      self.head.prev = node
    end
    self.head = node
    #START: move middle
    if self.head.next.nil?
      self.middle_node = self.head
      self.middle_index = self.size
    else
      new_middle_index = (self.size / 2.to_f).ceil
      return if self.middle_index == new_middle_index
      if new_middle_index > self.middle_index
        self.middle_index = new_middle_index
        self.middle_node = self.middle_node.prev
      end
    end
    #END: move middle
  end

  def pop()
    return if self.head.nil?

    data = self.head.data
    new_head = self.head.next
    new_head.prev = nil if new_head
    self.head.next = nil
    self.head = new_head
    self.size = self.size - 1
    #START: move middle
    new_middle_index = (self.size / 2.to_f).ceil
    if self.middle_index == new_middle_index
      self.middle_node = self.middle_node.prev
    elsif new_middle_index < self.middle_index
      self.middle_index = new_middle_index
      self.middle_node = self.middle_node.next
    end
    #END: move middle
    data
  end

  def find_middle()
    self.middle_node.data if self.middle_node
  end

  def delete_middle()
    return if self.middle_node.nil?
    self.size = self.size - 1
    if self.middle_node.prev
      self.middle_node.prev.next = self.middle_node.next
    end
    if self.middle_node.next
      self.middle_node.next.prev = self.middle_node.prev
    end

    return if self.head.nil?
    #START: move middle
    new_middle_index = (self.size / 2.to_f).ceil
    if self.middle_index == new_middle_index
      self.middle_node = self.middle_node.prev
    elsif new_middle_index < self.middle_index
      self.middle_index = new_middle_index
      self.middle_node = self.middle_node.next
    end
    #END: move middle
  end
end
#+END_SRC
*** (14) How to efficiently implement k stacks in a single array
start: 3:30
end: 4:30

top always refers to two positions:
  - arr; if top points to 8, then arr[8] contains the element
  - next; if top points to 8, then next[8] contains the *index* to the next node.

#+BEGIN_SRC ruby
class KArrayStack
  attr_accessor :arr, :top_arr, :next_arr, :free
  def initialize(k, capacity = 6)
    self.arr = Array.new(capacity)
    self.top_arr = Array.new(k, -1)
    self.next_arr = Array.new(capacity, -1)
    (0..capacity-2).each do |index|
      self.next_arr[index] = index + 1
    end
    self.free = 0
  end

  def push(ele, k)
    return if self.free == -1
    i = self.free
    self.free = self.next_arr[i]
    self.next_arr[i] = self.top_arr[k]
    self.top_arr[k] = i
    self.arr[i] = ele
  end

  def pop(k)
    return if self.top_arr[k] == -1

    ele = self.arr[self.top_arr[k]]
    self.arr[self.top_arr[k]] = nil
    i = self.free
    self.free = self.top_arr[k]
    self.top_arr[k] = self.next_arr[self.free]
    self.next_arr[self.free] = i
    ele
  end
end
#+END_SRC
*** (16) Length of the longest valid substring
start: 4:38
end: 4:47
#+BEGIN_SRC ruby
#HINT: Discuss this with Manoj
def length_longest_substring(str)
  stack = []
  counter = 0
  str.split("").each do |char|
    if char == ')' && stack[-1] == '('
      counter = counter + 2
      stack.pop
    else
      stack.push char
    end
  end
  counter
end
#+END_SRC
*** (17) Find maximum of minimum for every window size in a given array
start: 6:26
end: 7:12
#+BEGIN_SRC ruby
def max_of_the_min_window_o_n3(numbers)
  size = 1
  super_group = []
  while size != numbers.size + 1
    groups = []
    index = 0
    while index != numbers.size
      sub_index = index
      group = []
      while group.size != size && sub_index != numbers.size
        group << numbers[sub_index]
        sub_index = sub_index + 1
      end
      groups << group if group.size == size
      index = index + 1
    end
    super_group << groups.map{|group| group.min}.max
    size = size + 1
  end
  super_group
end

def max_of_the_min_window(numbers)
  groups = []
  index = 0
  while index != numbers.size
    groups << []
    index = index + 1
  end
  index = 0
  while index != numbers.size
    sub_index = 0
    while sub_index != index + 1
      groups[sub_index] << numbers[(index - sub_index)..index]
      sub_index = sub_index + 1
    end
    index = index + 1
  end
  groups.map{|group| group.map{|sub| sub.min}.max}
end

numbers = [10, 20, 30, 50, 10, 70, 30] * 10000;1
Benchmark.bm do |x|
  x.report { max_of_the_min_window numbers }
  x.report { max_of_the_min_window_o_n3 numbers }
end
#+END_SRC

*** String to Integer (atoi)
https://leetcode.com/problems/string-to-integer-atoi/#/description
#+BEGIN_SRC ruby
def my_atoi(str)
    #1.- Discard as many whitespaces as possible
    str.strip!
    return 0 if str.empty?
    #2.- checks for the sign
    sign = +1
    index = 0
    case str[index].ord
    when 43
        sign = +1
        index = 1
    when 45
        sign = -1
        index = 1
    else
        index = 0
    end
    zero = 48
    nine = 57
    stack = []
    while index < str.size
        ascii_index = str[index].ord
        if ascii_index >= zero and ascii_index <= nine
            stack.push(ascii_index - zero)
            index = index + 1
        else
            break
        end
    end
    exponent = 0
    total = 0
    while !stack.empty?
        total = total + stack.pop * 10**exponent
        exponent = exponent + 1
    end
    total = total * sign
    if total > 2147483647
        2147483647
    elsif total < -2147483648
        -2147483648
    else
        total
    end
end
#+END_SRC
** Queue
*** (1) Implement a Queue by using an Array
start: 7:25
end: 7:51
#+BEGIN_SRC ruby
class ArrayQueue
  attr_accessor :arr, :top, :free, :capacity
  def initialize(capacity = 50)
    self.arr = Array.new(capacity, nil)
    self.top = -1
    self.free = 0
    self.capacity = capacity
  end

  def front
    return if self.top == -1
    self.arr[self.top]
  end

  def enqueue(ele)
    return if self.top == self.free

    self.arr[self.free] = ele
    if self.top == -1
      self.top = self.free
    end
    self.free = (self.free + 1) % self.capacity
  end

  def dequeue
    return if self.top == -1

    ele = self.arr[self.top]
    self.arr[self.top] = nil
    self.top = (self.top + 1) % self.capacity
    if self.top == self.free
      self.top = -1
    end
    ele
  end
end
#+END_SRC
*** (2) Implement a Queue by using a LinkedList
start: 7:54
end: 8:06
#+BEGIN_SRC ruby
class Node
  attr_accessor :data, :next
  def initialize(data, next_node=nil)
    self.data = data
    self.next = next_node
  end
end

class LinkedListQueue
  attr_accessor :front, :rear
  def initialize
    self.front = self.rear = nil
  end

  def enqueue(ele)
    node = Node.new(ele)
    if self.front.nil?
      self.front = node
      self.rear = node
    else
      self.rear.next = node
      self.rear = node
    end
  end

  def dequeue
    return if self.front.nil?
    node = self.front
    self.front = self.front.next
    data = node.data
    node = nil
    data
  end
end
#+END_SRC
*** (3) Applications of Queue Data Structure
No exercises
*** (4) Priority Queue Implementation
  - Every item has a priority
  - Element with high priority is dequeued before an element with low priority
  - If two elements have the same priority, they are served according to their order in the queue
  - Applications
    - CPU Scheduling
    - All queue applications where priority is involved
*** (5) Deque or Double Ended Queue
  - Implementations
    - Doubly Linked List
    - Circular Array
*** (6) [READ AGAIN]Implementation of Deque using Circular Array
start: 5:15
end: 6:21
#+BEGIN_SRC ruby
class DequeCircularArray
  attr_accessor :arr, :front, :rear, :capacity
  def initialize(capacity)
    self.capacity = capacity
    self.arr = Array.new(self.capacity, nil)
    self.front = 0
    self.rear = 0
  end

  def insert_front(ele)
    return if is_full?
    if is_empty?
      self.arr[self.front] = ele
    else
      self.front = (self.front - 1) % self.capacity
      self.arr[self.front] = ele
    end
  end

  def insert_rear(ele)
    return if is_full?
    if is_empty?
      self.front = self.rear = 0
      self.arr[self.front] = ele
    else
      self.rear = (self.rear + 1) % self.capacity
      self.arr[self.rear] = ele
    end
  end

  def delete_front
    return if is_empty?
    self.arr[self.front] = nil
    if self.front == self.rear
      self.front = (self.front + 1) % self.capacity
      self.rear = self.front
    else
      self.front = (self.front + 1) % self.capacity
    end
  end

  def delete_rear
    return if is_empty?
    self.arr[self.rear] = nil
    if self.rear == self.front
      self.rear = (self.rear - 1) % self.capacity
      self.front = self.rear
    else
      self.rear = (self.rear - 1) % self.capacity
    end
  end

  def get_front
    return if is_empty?
    self.arr[self.front]
  end

  def get_rear
    return if is_empty?
    self.arr[self.rear]
  end

  def is_empty?
    self.arr[self.front].nil? && self.arr[self.rear].nil?
  end

  def is_full?
    (self.front - 1) % self.capacity == self.rear
  end
end
#+END_SRC
*** (7) [READ AGAIN]Implement Queue Using Stacks
start: 8:22
end: 8:29
#+BEGIN_SRC ruby
class QueueStacks
  attr_accessor :front_stack, :rear_stack
  def initialize
    self.front_stack = []
    self.rear_stack = []
  end

  def enqueue(ele)
    if self.front_stack.empty? && self.rear_stack.empty?
      self.front_stack.push ele
    else
      self.rear_stack.push ele
    end
  end

  def dequeue
    if !self.front_stack.empty?
      ele = self.front_stack.pop
    else
      while !self.rear_stack.empty?
        self.front_stack.push self.rear_stack.pop
      end
      ele = self.front_stack.pop
    end
    ele
  end
end
#+END_SRC
*** (8) [READ AGAIN]Check whether a binary tree is complete or not
start: 6:03
end: 7:45
#+BEGIN_SRC ruby
#HINT: I used the concept of levels, but that complicated things *a lot*
#Using the concept of Full Node(right && left != null) simplifies everything!
class MyNode
  attr_accessor :data, :left, :right
  def initialize(data, left=nil, right=nil)
    self.data = data
    self.left = left
    self.right = right
  end
end

def is_complete?(binary_tree)
  queue = []
  current_level = 0
  next_level = nil
  queue.push [binary_tree, 0]
  current_total = 0
  complete = true
  more_children_allowed = true
  while !queue.empty? do
    expected_total = 2**current_level
    current_total = 0
    next_level = current_level + 1
    while !queue.empty? && queue[0][1] != next_level do
      current_total = current_total + 1
      ele, current_level = queue.shift
      puts "#{!ele.right.nil?}, #{ele.left.nil?}"
      if !ele.right.nil? && ele.left.nil?
        complete = false
        break
      end
      if current_total == 1 && ele.left.nil?
        more_children_allowed = false
      end
      if (ele.right || ele.left) && !more_children_allowed
        complete = false
        break
      end
      queue.push [ele.left, next_level] if ele.left
      queue.push [ele.right, next_level] if ele.right
    end
    current_level = next_level
    break if complete == false
    if current_total != expected_total && more_children_allowed == true
      complete = false
      break
    end
  end
  complete
end
#+END_SRC
*** (10) [IMPLEMENT IT AGAIN]Find the first circular tour that visits all petrol pumps
runtime complexity: O(n)
extra space: O(n);;it should be posible O(1)
#+BEGIN_SRC ruby
class PetrolPump
  attr_accessor :petrol, :distance
  def initialize(petrol, distance)
    self.petrol = petrol
    self.distance = distance
  end
end

def circular_tour(pumps)
  good_pumps = []
  bad_pumps = []
  gas = 0
  current = 0
  while current < pumps.size
    if gas + pumps[current].petrol - pumps[current].distance > 0
      good_pumps.append current
      gas = gas + pumps[current].petrol - pumps[current].distance
    else
      while !good_pumps.empty?
        bad_pumps.append good_pumps.shift
      end
      bad_pumps.append current
    end
    current = current + 1
  end
  found = true
  while !bad_pumps.empty?
    current = bad_pumps.shift
    if gas + pumps[current].petrol - pumps[current].distance > 0
      good_pumps.append current
      gas = gas + pumps[current].petrol - pumps[current].distance
    else
      found = false
      break
    end
  end
  if found
    good_pumps[0]
  else
    -1
  end
end
#+END_SRC
*** (11) Sliding Window Maximum (Maximum of all subarrays of size k)
#+BEGIN_SRC ruby
def sliding_window_maximum(arr, k)
  deque = []
  (0..k-1).each do |index|
    while !deque.empty? && arr[index] > deque[-1]
      deque.pop
    end
    deque.push(index)
  end
  index = k
  while index != arr.size
    puts arr[deque[0]]
    while !deque.empty? && deque[0] <= index - k
      deque.shift
    end
    while !deque.empty? && arr[index] > arr[deque[-1]]
      deque.pop
    end
    deque.append(index)
    index = index + 1
  end
  puts arr[deque[0]]
end
#+END_SRC

** Exercises [8/9]
** Implementations
*** Hash Table
    - Compute key's hash code
    - Map the key's hash code to an index in the array
    - In that position we need to store the key and value
      - use a linked list
    - Is it possible to use a binary search tree?

      This implementation uses a linked list and a fixed size array
      #+BEGIN_SRC ruby
class Node
  attr_accessor :key, :value, :next_node
  def initialize(key, value, next_node = nil)
    self.key = key
    self.value = value
    self.next_node = next_node
  end
end

class EmptyNode
  attr_accessor :key, :value, :next_node
end

class LinkedList
  attr_accessor :first_node, :size

  def initialize(node = nil)
    node = node ? node : EmptyNode.new()
    self.first_node = node
    self.size = 1
  end

  def add(key, value)
    node = Node.new(key, value, self.first_node)
    self.first_node = node
    self.size += 1
    self
  end

  def find
    return if !block_given?

    current = self.first_node
    found = false
    self.size.times.each do
      found = yield current
      break if found
      current = current.next_node
    end
    current if found
  end
end

class MyHash
  attr_accessor :array, :size
  def initialize(size = nil)
    self.size = 50
    self.array = self.size.times.map do
      LinkedList.new()
    end
  end

  def add(key, value)
    hash_value = hash_for(key)
    array_index = hash_value % self.size
    self.array[array_index].add(key, value)
    self
  end

  def value(key)
    hash_value = hash_for(key)
    array_index = hash_value % self.size
    node = self.array[array_index].find do |node|
      node.key == key
    end
    node.value if node
  end

  private
  def hash_for(key)
    md5 = Digest::MD5.new
    md5.update(key.to_s).hexdigest.to_i
  end
end
      #+END_SRC

      This implementation is using BST
      #+BEGIN_SRC ruby
class TreeNode
  attr_accessor :key, :value, :left_node, :right_node
  def initialize(key, value, left_node = EmptyTreeNode.new, right_node = EmptyTreeNode.new)
    self.key = key
    self.value = value
    self.left_node = left_node
    self.right_node = right_node
  end

  def add(key, value)
    left_node = self.left_node
    right_node = self.right_node
    if key > self.key
      right_node = self.right_node.add(key, value)
    else
      left_node = self.left_node.add(key, value)
    end
    TreeNode.new(self.key, self.value, left_node, right_node)
  end

  def find_by(key)
    return self if key == self.key

    if key > self.key
      self.right_node.find_by(key)
    else
      self.left_node.find_by(key)
    end
  end
end

class EmptyTreeNode
  def add(key, value)
    TreeNode.new(key, value)
  end

  def find_by(key)
    self
  end

  def value
    nil
  end
end

class MyHashUsingBST
  attr_accessor :tree
  def initialize()
    self.tree = EmptyTreeNode.new
  end

  def add(key, value)
    self.tree = self.tree.add(key, value)
  end

  def value(key)
    self.tree.find_by(key).value
  end
end

m = MyHashUsingBST.new
m.add(:milton, 5)
m.add(:ivania, 10)
m.value(:milton)
m.value(:ivania)
    #+END_SRC

*** ArrayList & Resizable Arrays
    - Create an array with a fixed amount of elements
    - Insert data
    - When full expand it to the double

*** String Builder
    - sentence =  sentence + w -->  will create a new  string instance
      each time
    - StringBuilder uses an arraylist and concatenate all the elements
      at the end building a string

** Breadth Tree Traversal
  #+BEGIN_SRC ruby
  class Node < Struct.new(:data, :left, :right)
    def breadth(acc = "")
      queue = Queue.new
      queue << self
      while !queue.empty? do
        current = queue.pop
	acc += "#{current.data}-"
	queue << current.left if current.left
	queue << current.right if current.right
      end
      puts acc
    end
  end

  #         :a
  #    :b        :c
  # :d    :e  :f
  r = Node.new(:a, Node.new(:b, Node.new(:d), Node.new(:e)), Node.new(:c, Node.new(:f)))
  > r.breadth
  a-b-c-d-e-f-
  #+END_SRC

** Number of Islands
#+BEGIN_SRC ruby
class Matrix
  def []=(i, j, x)
    @rows[i][j] = x
  end
end

def number_of_islands(matrix)
  islands = 0
  matrix.each_with_index do |element, row_index, column_index|
    if element == 'X'
      islands = islands + 1
      flood_fill(matrix, row_index, column_index, '0')
    end
  end
  islands
end

def flood_fill(matrix, row_index, column_index, replacement)
  return if row_index < 0 || column_index < 0 || row_index >= matrix.row_size || column_index >= matrix.column_size || matrix.element(row_index, column_index) == replacement
  matrix[row_index, column_index] = replacement
  flood_fill(matrix, row_index - 1, column_index, replacement) #north
  flood_fill(matrix, row_index + 1, column_index, replacement) #south
  flood_fill(matrix, row_index, column_index - 1, replacement) #west
  flood_fill(matrix, row_index, column_index + 1, replacement) #east
end

#+END_SRC
** Make Change with Coins
#+BEGIN_SRC ruby
coins = [1, 2, 5]
total = 7
amounts = [99999] * (total+1)
amounts[0] = 0
(1..total).each do |amount|
  coins.each do |coin|
    next if coin > amount
    amounts[amount] = [amounts[amount-coin] + 1, amounts[amount]].min
  end
end
#+END_SRC
** Permutations
   - Permutations are for lists; order matters
   - permutation(1,2,3) -> [1,2,3], [3,2,1], [2,1,3]..
   - Think about "locks": 1 2 3 4 --> only one *permutation* will open the lock
   - How many ways can we award 1st, 2nd, 3rd place prize among 3 people?
     - for gold medal, we have 8 choices
     - after choosing the gold medal, we have 7 choices for silver medal
     - after choosing the silver medal, we have 6 choices for bronce medal
     - Thus, 8*7*6 = 336
       - We know that 8! = 8*7*6*5*4*3*2*1, but we want to stop at "5"
       - 5! == 8!/5! == 8!/(8 - 3)! == n!/(n - k)!
     - n!/(n - k)! --> we have n items and we want to pick "k" of them in different order

   - There are two ways of think about of generating permutations:
     - We can think of having a function that already knows how to generate permutations, and then we want
       to add a new element. Then the element needs to be added in each position of each element of the resulting set
       - The implementation of this is a recursive algorithm.
       #+BEGIN_SRC ruby
def insert(element, array)
  result = []
  index = 0
  while index < array.size + 1
    arr = array.dup
    tmp = arr[index]
    arr[index] = element
    arr.insert(index + 1, tmp) if tmp
    result << arr
    index = index + 1
  end
  result
end

def permutation(array)
  return [array] if array.size == 1
  result = []
  permutation(array[1..-1]).each do |partial_permutation|
    result << insert(array[0], partial_permutation)
  end
  result.flatten(1)
end
#+END_SRC
     - We can think of generating the permutation by swapping elements in each level.
       #+BEGIN_SRC ruby
#swapping elements in each level
def swap(array, i, j)
  tmp = array[i]
  array[i] = array[j]
  array[j] = tmp
end

def permutation(array, start, stop, result)
  if start == stop
    return result << array.dup
  end
  index = start
  while index <= stop
    swap(array, start, index)
    permutation(array, start + 1, stop, result)
    swap(array, start, index) #backtracking, this move the element back to its original position
    index = index + 1
  end
end
#+END_SRC
** Combinations
  - It's for groups (order does not matter)
  - combination([1,2,3]) --> [1,2,3]
  - To generate a combination of numbers a group size is needed
    - combination([1,2,3], 2)
      - [1,2], [1,3], [2,3]
      - 3!/(3-2)!*2! == 6/2 == 3 (how many new sets need to be generated)
#+BEGIN_SRC ruby
def combination_util(index, array, template, result, group)
  array[index..-1].each_with_index do |ele, ind|
    if template.size == group - 1
      result << template + [ele]
    else
      combination_util(index + ind + 1, array, template + [ele], result, group)
    end
  end
end

def combination(array, group_size)
  result = []
  #I want each element of array 'array' to be the header
  #of the template array. Template array is used to compute a valid
  #array once group size is reached. the resulting array is stored in result
  array.each_with_index do |element, index|
    combination_util(index + 1, array, [element], result, group_size)
  end
  result
end
#+END_SRC
** Dynamic Programming
*** Minimum Number of Jumps to reach end
#+BEGIN_SRC ruby
def max_index(arr, start_index, size)
  index = 0
  max = -1
  index_max = -1
  while index < size && index + start_index < arr.size
    if arr[start_index + index] > max
      max = arr[start_index + index]
      index_max = index
    end
    index = index + 1
  end
  index_max + 1
end

def min_jumps(arr)
  steps = 0
  index = 0
  while index < arr.size
    if arr[index] == 0
      steps = -1
      break
    end
    steps = steps + 1
    break if index + arr[index] >= arr.size
    max = max_index(arr, index + 1, arr[index])
    index = index + max
  end
  steps
end
#+END_SRC
*** Minimum Number of Coins
#+BEGIN_SRC ruby
def min_coins(amount, coins)
  dp = Array.new(amount + 1, 0)
  # 1 + min of coins each {|coin| dp[amount - coin] if (amount - coin) >= 0 }
  (1..amount).each do |current_amount|
    coins.each do |coin|
      break if (current_amount - coin) < 0
      dp[current_amount] = 1 + dp[current_amount - coin]
    end
  end
  dp[amount]
end

def give_change(amount, coins)
  dp_amount = Array.new(amount + 1, 0)
  dp_change = Matrix.build(amount + 1, coins.size){|_row, _column| 0}
  (1..amount).each do |current_amount|
    selected_coin_index = -1
    selected_coin = -1
    coins.each_with_index do |coin, index|
      break if (current_amount - coin) < 0
      dp_amount[current_amount] = 1 + dp_amount[current_amount - coin]
      selected_coin_index = index
      selected_coin = coin
    end
    prev = dp_change.send(:rows)[current_amount - selected_coin].dup
    prev[selected_coin_index] += 1
    dp_change.send(:rows)[current_amount] = prev
  end
  {
    number_of_coins: dp_amount[amount],
    coins: dp_change.send(:rows)[amount]
   }
end

#+END_SRC
* Learnings
  - Use paper and pencil or whiteboard
  - Make sure to have an example of expected input and output
  - Make sure you have different examples
  - Think about arguments and return type
  - Come up with a quick solution
  - Think about edge cases
  - Worry about runtime complexity
  - Worry about space complexity
  - Define everything in just one function if you are using Ruby + LinkedLists
  - Remember that you can modify a data structure
  - Do you need to collect the data or just print it?
  - You can delete elements of the set of the solution when they are not useful anymore
    - Stack: (7)
  - Swapping name of data structures when necessary
    - Stack: (12)
  - Visualize in a better way the solutions; ask you if you already have the answer
  - Use the API of the data structure when extra space is not allowed
  - Check what happen with the Data Structure after performing an operation. Work with real life examples.
  - When calculating the middle keep in mind even and odd results
  - Circular indexes can go negative or around an array
  - When solving problems with circular arrays, you can traverse the array twice if you want.
  - When solving recursive problems using a stack you have to be aware that's harder to any "backtracking" operations
    - mark a node as being processed and after processing all its children unmark it.
* Resources [1/4]
  - Data Structures
    - https://www.youtube.com/watch?v=YWnBbNj_G-U
    - Big O notation: 36:02
  - Dynamic Programming
    - https://www.topcoder.com/community/data-science/data-science-tutorials/dynamic-programming-from-novice-to-advanced/
  - Cracking the Coding Interviews Video
    - https://www.youtube.com/watch?v=GKgAVjJxh9w&list=PLX6IKgS15Ue02WDPRCmYKuZicQHit9kFt&index=1
  - Bit Manipulation
    - https://stackoverflow.com/questions/141525/what-are-bitwise-shift-bit-shift-operators-and-how-do-they-work
    - https://stackoverflow.com/questions/31575691/what-is-a-bitmask-and-a-mask
    - http://www.vipan.com/htdocs/bitwisehelp.html
    - http://codeforces.com/blog/entry/18169
    - https://www.cs.umd.edu/class/sum2003/cmsc311/Notes/BitOp/xor.html
  - Tech Interview Mindset
    - https://hackernoon.com/tech-interview-mindset-7485856ddfcf
  - How not to bomb your offer negotiation
    - https://medium.freecodecamp.org/how-not-to-bomb-your-offer-negotiation-c46bb9bc7dea
  - [ ] Purely Functional Data Structures
    - https://www.cs.cmu.edu/~rwh/theses/okasaki.pdf
  - [X] The Value of Values with Rich Hickey
    - https://www.youtube.com/watch?v=-6BsiVyC1kM
    - Information -> a fact -> a value not a place!
    - Objects are abstractions of a place in memory
    - Place-Oriented Programming
      - new information replaces old
    - Memory is an associative system
    - A fact is something that happened
    - You cannot update a fact
    - new facts will require new places!
  - [ ] Understand the CAP theorem
  - [ ] Make sure you're familiar with databases that select different letters in CAP
    - https://martin.kleppmann.com/2015/05/11/please-stop-calling-databases-cp-or-ap.html
* TODOs [2/18]
  - [ ] Dynamic Programming
    - http://www.geeksforgeeks.org/?p=12635
  - [ ] Dijkstra's Shortest Path
    - http://www.geeksforgeeks.org/?p=27697
  - [ ] Solve coin change problem by using "5 'easy' steps"
  - [ ] Solve min replacement problem
    - https://leetcode.com/problems/edit-distance/#/description
    - remember to use a matrix: a-b-c; x-y-z;
    - solve it by using "5 'easy' steps"
  - [ ] Minimum Height Trees
    - https://leetcode.com/problems/minimum-height-trees/#/description
  - [ ] https://leetcode.com/problems/binary-tree-postorder-traversal/#/description
  - [ ] https://leetcode.com/problems/the-skyline-problem/#/description
  - [ ] https://leetcode.com/problems/construct-binary-tree-from-inorder-and-postorder-traversal/#/description
  - [ ] https://leetcode.com/problems/construct-binary-tree-from-preorder-and-inorder-traversal/#/description
  - [ ] https://leetcode.com/problems/contains-duplicate-ii/#/description
  - [ ] https://leetcode.com/problems/binary-watch/#/description
  - [ ] https://www.cs.umd.edu/class/sum2003/cmsc311/Notes/BitOp/xor.html
  - [ ] https://leetcode.com/problems/total-hamming-distance/#/description
  - [ ] Extreme Cleverness: Functional Data Structures in Scala
    - https://www.infoq.com/presentations/Functional-Data-Structures-in-Scala
  - [ ] https://leetcode.com/problems/house-robber/#/description
  - [ ] https://leetcode.com/problems/house-robber-iii/#/description
  - [X] https://leetcode.com/problems/binary-tree-level-order-traversal-ii
  - [X] https://leetcode.com/problems/find-bottom-left-tree-value
* Cracking the Coding Interview Videos
** 7 Steps to Solve Algorithm Problems
  1. Listen
     1. make sure you use every detail of the problem description when finding a solution
  2. Example
     1. Large examples
     2. Avoid special cases
  3. Brute Force
     1. It's better to have a brute force solution than nothing at all
     2. State the algorithm
     3. State the runtime
     4. *but* do not code it
     5. Optimize!
  4. Optimize
     1. A big portion of the interview will be spent here.
  5. Walk through your algorithm
     1. What variables & data structures
     2. How, When + Why do they change?
     3. What's the structure of your code
  6. Code
     1. Whiteboard
        1. write straight
        2. use space wisely
           1. erase what you don't need
           2. okay to use arrows
           3. write in the top-left corner
     2. Whiteboard-or-Computer
        1. coding style matters
           1. consistent braces
           2. consistent variable naming
           3. consistent spaces
           4. descriptive variable names
              1. ask your interviewer if you can shorten the name after you used it.
        2. Modularize
           1. do this *before* and not *after
           #+BEGIN_SRC ruby
           def doSomething(a, b){
           r = processString(a)
           s = processString(b)
           compareResults(r, s)
           }
           #+END_SRC
  7. Test
     1. Walk through the *code* and make sure that each line is doing what's suppose to do
     2. Use small test cases
     3. Edge cases
     4. Big test cases!! if you have time
     5. Make sure you are testing the code --> route your code
     6. If you find a bug don't panic! understand why it's failing
** 3 Algorithm Strategies
  1. B.U.D.
     1. B -> Bottleneck; walk through brute force solution
     2. U -> Unnecessary Work; see what's causing the runtime complexity to go up
     3. D -> Duplicated Work; how can I avoid doing things over and over again
        1. Store partial results in an additional data structure
  2. Space/Time tradeoffs
     1. Try hash tables first!!
  3. D.I.Y
     1. Do It Yourself
     2. Come up with a big example without edge cases
        1. This will help your brain to come up with a solution
** Behavioral Questions
  - Headline: I'm a software engineer at ""
  - Beginning of career: I hold a master and a bachelor in computer science.
  - Go through forward chronologically: do this quickly
  - Quick show of success
    - a feature you built
    - promotion
    - award
  - Key stories
    - Drive recruiter in the direction you want
  - Hobbies
    - Technical --> erlang, projects
    - non-technical --> try to make them relevant
  - Pick Projects
    - Biggest challenges
    - Architecture
    - Technologies
    - Soft skills
      - Team work dynamics
      - how you do differently
  - Be open to talk about your failures!!
  - Communicate your thought process! -> technical interviews
** Hash Table
** Graph Search (DFS and BFS)
** Anagram Problem Solution
  - Anagram is a permutation of a word
  - same letters, same counts, different order!
  - hello vs billion => 6 deletions are needed to find an anagram
  - the solution is to create a hash table for each word. each key will represent a char and the value of it will be a counter of the occurrences of that char in the string
    - do this for both strings
    - compute the difference between each char and sum them all. The result is how many deletions are needed.
** Bit Manipulation
** Solution for the Contacts problem
